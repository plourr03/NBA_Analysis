{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2d00927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pyodbc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from random import randint\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from utils import *\n",
    "from slugify import slugify\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c846d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'localhost\\SQLEXPRESS'\n",
    "database = 'nba_game_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e982dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = ''\n",
    "final_model_cv_score = 0\n",
    "final_model_score = 0\n",
    "final_scoring_type = 'career'\n",
    "final_dataset = -999\n",
    "type_of_data = 'noraml_normal'\n",
    "final_x_transformer = None\n",
    "base_score = 0 \n",
    "final_X = None\n",
    "final_y = None\n",
    "def model(player_id, pt_thresh, opp, over_or_under = 'over'):\n",
    "    global final_X,final_y,final_model, final_model_cv_score, final_model_score, final_scoring_type, final_dataset, type_of_data, final_x_transformer, base_score\n",
    "    if over_or_under == 'under':\n",
    "        line_sign = '<'\n",
    "    else:\n",
    "        line_sign = '>'\n",
    "    sql = f'''\n",
    "    with base as (\n",
    "    SELECT\n",
    "           pgl.[SEASON_YEAR]\n",
    "          ,pgl.[PLAYER_ID]\n",
    "          ,pgl.[PLAYER_NAME]\n",
    "          ,pgl.[NICKNAME]\n",
    "          ,pgl.[TEAM_ID]\n",
    "          ,pgl.[TEAM_ABBREVIATION]\n",
    "          ,pgl.[TEAM_NAME]\n",
    "          ,pgl.[GAME_ID]\n",
    "          ,pgl.[GAME_DATE]\n",
    "          ,LAG (pgl.[GAME_DATE]) OVER (PARTITION BY pgl.[PLAYER_ID] ORDER BY pgl.[GAME_DATE]) AS Last_Game_Played\n",
    "          ,pgl.[MATCHUP]\n",
    "          ,pgl.[WL]\n",
    "          ,pgl.[yearSeason]\n",
    "          ,CASE WHEN PGL.WL = 'W' THEN 1 ELSE 0 END AS WLInt\n",
    "          ,LAG (CASE WHEN PGL.WL = 'W' THEN 1 ELSE 0 END) OVER (PARTITION BY pgl.[PLAYER_ID] ORDER BY pgl.[GAME_DATE]) AS did_they_win_last_game\n",
    "         ,PTS\n",
    "      FROM [nba_game_data].[dbo].[PlayerGameLogs] pgl\n",
    "\n",
    "\n",
    "      WHERE pgl.PLAYER_ID = '{player_id}'\n",
    "      )\n",
    "      SELECT \n",
    "     [PLAYER_ID]\n",
    "    ,[GAME_ID]\n",
    "    ,[GAME_DATE]\n",
    "    ,yearSeason\n",
    "    ,[PTS]\n",
    "    ,CASE WHEN [PTS] {line_sign} {pt_thresh} THEN 1 ELSE 0 END AS PtsThreshold\n",
    "    ,SUM(WLInt) OVER (PARTITION BY PLAYER_ID ORDER BY GAME_DATE ROWS BETWEEN 11 PRECEDING AND 1 PRECEDING) AS RunningGamesWonLast10\n",
    "    ,DATEDIFF(day, Last_Game_Played,[GAME_DATE])-1 AS daysRest\n",
    "    ,did_they_win_last_game\n",
    "\n",
    "      FROM base\n",
    "\n",
    "      order by GAME_DATE\n",
    "\n",
    "    '''\n",
    "    cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';')\n",
    "    cursor = cnxn.cursor()\n",
    "    data = pd.read_sql(sql,cnxn)\n",
    "\n",
    "    sql = f'''\n",
    "    with base as (\n",
    "    SELECT\n",
    "           pgl.[SEASON_YEAR]\n",
    "          ,pgl.[PLAYER_ID]\n",
    "          ,pgl.[PLAYER_NAME]\n",
    "          ,pgl.[NICKNAME]\n",
    "          ,pgl.[TEAM_ID]\n",
    "          ,pgl.[TEAM_ABBREVIATION]\n",
    "          ,pgl.[TEAM_NAME]\n",
    "          ,pgl.[GAME_ID]\n",
    "          ,pgl.[GAME_DATE]\n",
    "          ,LAG (pgl.[GAME_DATE]) OVER (PARTITION BY pgl.[PLAYER_ID] ORDER BY pgl.[GAME_DATE]) AS Last_Game_Played\n",
    "          ,pgl.[MATCHUP]\n",
    "          ,pgl.[WL]\n",
    "          ,CASE WHEN PGL.WL = 'W' THEN 1 ELSE 0 END AS WLInt\n",
    "\n",
    "\n",
    "      FROM [nba_game_data].[dbo].[PlayerGameLogs] pgl\n",
    "\n",
    "\n",
    "\n",
    "      WHERE pgl.PLAYER_ID = '{player_id}'\n",
    "      )\n",
    "      SELECT \n",
    "     [PLAYER_ID]\n",
    "    ,[GAME_ID]\n",
    "    ,SUM(WLInt) OVER (PARTITION BY PLAYER_ID ORDER BY GAME_DATE ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS RunningGamesWonLast10\n",
    "    ,DATEDIFF(day, [GAME_DATE], GETDATE())-1 AS daysRest\n",
    "    ,WLInt AS did_they_win_last_game\n",
    "\n",
    "      FROM base\n",
    "\n",
    "      order by GAME_DATE\n",
    "\n",
    "    '''\n",
    "    cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';')\n",
    "    cursor = cnxn.cursor()\n",
    "    pred = pd.read_sql(sql,cnxn)\n",
    "\n",
    "    numbers = [2,5,10,20]\n",
    "\n",
    "    for i in numbers:\n",
    "        temp = get_player_last_n_data(player_id,i)\n",
    "        temp = temp.drop(columns = ['TEAM_ABBREVIATION','oppAbrv'])\n",
    "        data = pd.merge(data, temp, on=['PLAYER_ID', 'GAME_ID'])\n",
    "        del temp\n",
    "\n",
    "        temp = get_pred_data(player_id,i,opp)\n",
    "\n",
    "        pred = pd.merge(pred, temp, on=['PLAYER_ID', 'GAME_ID'])\n",
    "        del temp\n",
    "\n",
    "    pred = pred.iloc[-1:].drop(columns=['PLAYER_ID','GAME_ID'])\n",
    "\n",
    "    # Determine outliers using the IQR method\n",
    "    Q1 = data['PTS'].quantile(0.25)\n",
    "    Q3 = data['PTS'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define bounds for the outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Filter out outliers\n",
    "    data = data[(data['PTS'] >= lower_bound) &\n",
    "                                               (data['PTS'] <= upper_bound)]\n",
    "    filtered = data.loc[(data['PTS'] < (pt_thresh - 3)) | (data['PTS'] > (pt_thresh + 3))]#['PTS']\n",
    "    df_season_buffer = filtered.sort_values(by='GAME_DATE').tail(82)\n",
    "    df_season_buffer = df_season_buffer.drop(columns=['PLAYER_ID','GAME_ID','GAME_DATE','PTS','yearSeason'])\n",
    "\n",
    "    df_last_60 = data.tail(60)\n",
    "    df_last_60 = df_last_60.drop(columns=['PLAYER_ID','GAME_ID','GAME_DATE','PTS','yearSeason'])\n",
    "    df_season = data.loc[data['yearSeason']=='2024']\n",
    "    df_season = df_season.drop(columns=['PLAYER_ID','GAME_ID','GAME_DATE','PTS','yearSeason'])\n",
    "    df = data.drop(columns=['PLAYER_ID','GAME_ID','GAME_DATE','PTS','yearSeason'])\n",
    "    df = df.iloc[1:]\n",
    "\n",
    "    # Function to select top 'n' features\n",
    "    def select_top_n_features(X, y, n):\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X, y)\n",
    "\n",
    "        selector = SelectFromModel(model, max_features=n, prefit=True)\n",
    "        X_selected = selector.transform(X)\n",
    "        return X_selected, selector\n",
    "\n",
    "    # Modified function to evaluate models with feature selection\n",
    "    def evaluate_models_with_feature_selection(df_feat, X, y, n_features, dataset_type, type_data):\n",
    "        global final_model, final_model_cv_score, final_model_score, final_scoring_type, final_dataset, type_of_data, base_score, final_X, final_y, final_x_transformer\n",
    "\n",
    "        X_selected, selector = select_top_n_features(X, y, n_features)\n",
    "        scoring_method = 'precision'  # Change to 'f1_macro', 'f1_micro', or 'f1_weighted' for multi-class\n",
    "\n",
    "        if len(df_feat) < 100:\n",
    "            cv_strategy = LeaveOneOut()\n",
    "        else:\n",
    "            cv_strategy = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "\n",
    "        for name, model in models.items():\n",
    "            cv_scores = np.mean(cross_val_score(model, X_selected, y, cv=cv_strategy, scoring=scoring_method, n_jobs=-1))\n",
    "            if name == 'Bayesian' and cv_scores == final_model_cv_score:\n",
    "                cv_scores += 0.001\n",
    "\n",
    "            if cv_scores > final_model_cv_score:\n",
    "                final_model = name\n",
    "                final_model_cv_score = cv_scores\n",
    "                final_model_score = cv_scores - base_score\n",
    "                final_scoring_type = 'loo' if len(df_feat) < 100 else 'cv'\n",
    "                final_dataset = dataset_type\n",
    "                type_of_data = type_data\n",
    "                final_X = X_selected\n",
    "                final_y = y\n",
    "                final_x_transformer = selector\n",
    "\n",
    "\n",
    "    # Function to evaluate models\n",
    "    def evaluate_models(df_current, X, y, dataset_type, type_data, pca_transformer = None):\n",
    "        global final_model, final_model_cv_score, final_model_score, final_scoring_type, final_dataset, type_of_data, base_score, final_X, final_y, final_x_transformer\n",
    "\n",
    "        scoring_method = 'precision'  # Change to 'f1_macro', 'f1_micro', or 'f1_weighted' for multi-class\n",
    "\n",
    "        if len(df_current) < 100:\n",
    "            cv_strategy = LeaveOneOut()\n",
    "        else:\n",
    "            cv_strategy = KFold(n_splits=15, shuffle=True, random_state=42)\n",
    "\n",
    "        for name, model in models.items():\n",
    "            cv_scores = np.mean(cross_val_score(model, X, y, cv=cv_strategy, scoring=scoring_method, n_jobs=-1))\n",
    "            if name == 'Bayesian' and cv_scores == final_model_cv_score:\n",
    "                cv_scores += 0.001\n",
    "\n",
    "            if cv_scores > final_model_cv_score:\n",
    "                final_model = name\n",
    "                final_model_cv_score = cv_scores\n",
    "                final_model_score = cv_scores - base_score\n",
    "                final_scoring_type = 'loo' if len(df_current) < 100 else 'cv'\n",
    "                final_dataset = dataset_type\n",
    "                type_of_data = type_data\n",
    "                final_X = X\n",
    "                final_y = y\n",
    "                final_x_transformer = pca_transformer\n",
    "\n",
    "                base_score = sum(df['PtsThreshold'])/ len(df) \n",
    "    final_model = ''\n",
    "    final_model_cv_score = 0\n",
    "    final_model_score = 0\n",
    "    final_scoring_type = 'career'\n",
    "    final_dataset = -999\n",
    "    type_of_data = 'noraml_normal'\n",
    "    final_x_transformer = None\n",
    "\n",
    "\n",
    "    final_X = None\n",
    "    final_y = None\n",
    "\n",
    "    max_feat_5_pct = round(len(df)*.05)\n",
    "    max_feat_10_pct = round(len(df)*.10)\n",
    "\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "    # Separating features and target\n",
    "    X = df.drop('PtsThreshold', axis=1)\n",
    "    y = df['PtsThreshold']\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca = PCA(n_components=0.95) # Adjust the number of components as needed\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca_n_com = PCA(n_components=max_feat_5_pct) # Adjust the number of components as needed\n",
    "    X_pca_n_comp = pca_n_com.fit_transform(X_scaled)\n",
    "\n",
    "    # Models\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "#         \"XGBoost\": XGBClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"Bayesian\": GaussianNB(),\n",
    "    }\n",
    "\n",
    "    base_score = sum(df_last_60['PtsThreshold'])/ len(df_last_60) \n",
    "\n",
    "    max_feat_5_pct = round(len(df)*.05)\n",
    "    max_feat_10_pct = round(len(df)*.10)\n",
    "\n",
    "    df_last_60.fillna(df_last_60.mean(), inplace=True)\n",
    "\n",
    "    # Separating features and target\n",
    "    X = df_last_60.drop('PtsThreshold', axis=1)\n",
    "    y = df_last_60['PtsThreshold']\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca = PCA(n_components=0.95) # Adjust the number of components as needed\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca_n_com = PCA(n_components=max_feat_5_pct) # Adjust the number of components as needed\n",
    "    X_pca_n_comp = pca_n_com.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "    # # Evaluating models without dimensionality reduction\n",
    "    # print(\"Evaluating models without dimensionality reduction:\")\n",
    "    # evaluate_models(df_last_60,X_scaled, y,'60','normal_normal')\n",
    "\n",
    "    # Evaluating models with dimensionality reduction\n",
    "    # print(\"\\nEvaluating models with dimensionality reduction:\")\n",
    "    evaluate_models(df_last_60,X_pca, y,'60','pca_95', pca)\n",
    "\n",
    "    # Evaluating models with dimensionality reduction only n comp\n",
    "    # print(\"\\nEvaluating models with dimensionality reduction only n comp:\")\n",
    "    evaluate_models(df_last_60,X_pca_n_comp, y,'60','pca_n',pca_n_com)\n",
    "\n",
    "    # Example of how to use the modified function\n",
    "    # print(\"\\nEvaluating models with top 5% feature selection:\")\n",
    "    evaluate_models_with_feature_selection(df_last_60,X_scaled, y, max_feat_5_pct,'60','selection_5')  \n",
    "\n",
    "    # Example of how to use the modified function\n",
    "    # print(\"\\nEvaluating models with top 10% feature selection:\")\n",
    "    evaluate_models_with_feature_selection(df_last_60,X_scaled, y, max_feat_10_pct,'60','selection_10')  \n",
    "\n",
    "    df_season.fillna(df_season.mean(), inplace=True)\n",
    "    base_score = sum(df_season['PtsThreshold'])/ len(df_season) \n",
    "\n",
    "    # Separating features and target\n",
    "    X = df_season.drop('PtsThreshold', axis=1)\n",
    "    y = df_season['PtsThreshold']\n",
    "\n",
    "    max_feat_5_pct = round(len(df_season)*.05)\n",
    "    max_feat_10_pct = round(len(df_season)*.10)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca = PCA(n_components=0.95) # Adjust the number of components as needed\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca_n_com = PCA(n_components=max_feat_10_pct) # Adjust the number of components as needed\n",
    "    X_pca_n_comp = pca_n_com.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "    # # Evaluating models without dimensionality reduction\n",
    "    # print(\"Evaluating models without dimensionality reduction:\")\n",
    "    # evaluate_models(df_season,X_scaled, y, 'season','normal_normal')\n",
    "\n",
    "    # Evaluating models with dimensionality reduction\n",
    "    # print(\"\\nEvaluating models with dimensionality reduction:\",'pca_95', pca)\n",
    "    evaluate_models(df_season,X_pca, y,'season','pca_95',pca)\n",
    "\n",
    "    # Evaluating models with dimensionality reduction only n comp\n",
    "    # print(\"\\nEvaluating models with dimensionality reduction only n comp:\",pca_n_com)\n",
    "    evaluate_models(df_season,X_pca_n_comp, y,'season','pca_n',pca_n_com)\n",
    "\n",
    "    # Example of how to use the modified function\n",
    "    # print(\"\\nEvaluating models with top 5% feature selection:\")\n",
    "    evaluate_models_with_feature_selection(df_season,X_scaled, y, max_feat_5_pct,'season','selection_5')  \n",
    "\n",
    "    # Example of how to use the modified function\n",
    "    # print(\"\\nEvaluating models with top 10% feature selection:\")\n",
    "    evaluate_models_with_feature_selection(df_season,X_scaled, y, max_feat_10_pct,'season','selection_10')  \n",
    "    \n",
    "    base_score = sum(df_season_buffer['PtsThreshold'])/ len(df_season_buffer) \n",
    "\n",
    "    max_feat_5_pct = round(len(df_season_buffer)*.05)\n",
    "    max_feat_10_pct = round(len(df_season_buffer)*.10)\n",
    "\n",
    "    df_season_buffer.fillna(df_season_buffer.mean(), inplace=True)\n",
    "\n",
    "    # Separating features and target\n",
    "    X = df_season_buffer.drop('PtsThreshold', axis=1)\n",
    "    y = df_season_buffer['PtsThreshold']\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca = PCA(n_components=0.95) # Adjust the number of components as needed\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca_n_com = PCA(n_components=max_feat_5_pct) # Adjust the number of components as needed\n",
    "    X_pca_n_comp = pca_n_com.fit_transform(X_scaled)\n",
    "\n",
    "    # Evaluating models with dimensionality reduction\n",
    "    evaluate_models(df_season_buffer,X_pca, y,'buffer','pca_95', pca_transformer = pca)\n",
    "\n",
    "    # Evaluating models with dimensionality reduction only n comp\n",
    "    evaluate_models(df_season_buffer,X_pca_n_comp, y,'buffer','pca_n',pca_transformer = pca_n_com)\n",
    "\n",
    "    # Example of how to use the modified function\n",
    "    evaluate_models_with_feature_selection(df_season_buffer,X_scaled, y, max_feat_5_pct,'buffer','selection_5')  \n",
    "\n",
    "    # Example of how to use the modified function\n",
    "    evaluate_models_with_feature_selection(df_season_buffer,X_scaled, y, max_feat_10_pct,'buffer','selection_10') \n",
    "\n",
    "    if final_model == 'Logistic Regression':\n",
    "        print('lr')\n",
    "        best_score = 0\n",
    "        tracker = 0\n",
    "#         while best_score < final_model_cv_score:\n",
    "        params, best_score = perform_hyper_param_tuning_bayes_lr(final_X, final_y, randint(0, 20000))\n",
    "#             if tracker == 2:\n",
    "#                 break\n",
    "#             tracker += 1\n",
    "\n",
    "        lr = LogisticRegression(**params).fit(final_X, final_y)\n",
    "\n",
    "        # Get predicted probabilities for the positive class on the training set\n",
    "        prob_positive_class_train = lr.predict_proba(final_X)[:, 1]\n",
    "\n",
    "        # Find the best threshold using training set\n",
    "        best_threshold = find_best_threshold(prob_positive_class_train, final_y)\n",
    "\n",
    "        # Prediction of probabilities on the test set\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            transformed_X_test = final_x_transformer.transform(pred)\n",
    "            prob_positive_class_test = lr.predict_proba(transformed_X_test)[:, 1]\n",
    "        else:\n",
    "            prob_positive_class_test = lr.predict_proba(pred)[:, 1]\n",
    "\n",
    "        # Apply the custom threshold to make final binary prediction\n",
    "        final_prediction = np.where(prob_positive_class_test > best_threshold, 1, 0)\n",
    "\n",
    "        # Assuming you are interested in the first prediction if 'pred' contains multiple samples\n",
    "        prediction = final_prediction[0]\n",
    "    elif final_model == 'Bayesian':\n",
    "        print('nb')\n",
    "        best_score = 0\n",
    "        tracker = 0\n",
    "#         while best_score < final_model_cv_score:\n",
    "        params, best_score = perform_hyper_param_tuning_bayes_nb(final_X, final_y, randint(0, 20000))\n",
    "#             if tracker == 2:\n",
    "#                 break\n",
    "#             tracker += 1\n",
    "\n",
    "        nb = GaussianNB(**params).fit(final_X, final_y)\n",
    "        loo = LeaveOneOut()\n",
    "\n",
    "        # Get predicted probabilities for the positive class on the training set\n",
    "        prob_positive_class_train = nb.predict_proba(final_X)[:, 1]\n",
    "\n",
    "        # Find the best threshold using training set\n",
    "        best_threshold = find_best_threshold(prob_positive_class_train, final_y)\n",
    "\n",
    "        # Cross-validation for model accuracy\n",
    "        scores = cross_val_score(nb, final_X, final_y, cv=loo, n_jobs=-1)\n",
    "\n",
    "        # Prediction of probabilities on the test set\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            transformed_X_test = final_x_transformer.transform(pred)\n",
    "            prob_positive_class_test = nb.predict_proba(transformed_X_test)[:, 1]\n",
    "        else:\n",
    "            prob_positive_class_test = nb.predict_proba(pred)[:, 1]\n",
    "\n",
    "        # Apply the custom threshold to make final binary prediction\n",
    "        final_prediction = np.where(prob_positive_class_test > best_threshold, 1, 0)\n",
    "\n",
    "        prediction = final_prediction[0]\n",
    "        # Assuming you are interested in the first prediction if 'pred' contains multiple samples\n",
    "\n",
    "    elif final_model == 'Decision Tree':\n",
    "        print('dt')\n",
    "        best_score = 0\n",
    "        tracker = 0\n",
    "#         while best_score < final_model_cv_score:\n",
    "        params, best_score = perform_hyper_param_tuning_bayes_dt(final_X, final_y, randint(0, 20000))\n",
    "#             if tracker == 2:\n",
    "#                 break\n",
    "#             tracker += 1\n",
    "\n",
    "        dt = DecisionTreeClassifier(**params).fit(final_X, final_y)\n",
    "\n",
    "        # Get predicted probabilities for the positive class on the training set\n",
    "        prob_positive_class_train = dt.predict_proba(final_X)[:, 1]\n",
    "\n",
    "        # Find the best threshold using training set\n",
    "        best_threshold = find_best_threshold(prob_positive_class_train, final_y)\n",
    "\n",
    "        # Prediction of probabilities on the test set\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            transformed_X_test = final_x_transformer.transform(pred)\n",
    "            prob_positive_class_test = dt.predict_proba(transformed_X_test)[:, 1]\n",
    "        else:\n",
    "            prob_positive_class_test = dt.predict_proba(pred)[:, 1]\n",
    "\n",
    "        # Apply the custom threshold to make final binary prediction\n",
    "        final_prediction = np.where(prob_positive_class_test > best_threshold, 1, 0)\n",
    "\n",
    "        prediction = final_prediction[0]\n",
    "        # Assuming you are interested in the first prediction if 'pred' contains multiple samples\n",
    "\n",
    "    elif final_model == 'Random Forest':\n",
    "        best_score = 0\n",
    "        tracker = 0\n",
    "#         while best_score < final_model_cv_score:\n",
    "        params, best_score = perform_hyper_param_tuning_bayes_rf(final_X, final_y, randint(0, 20000))\n",
    "#             if tracker == 2:\n",
    "#                 break\n",
    "#             tracker += 1\n",
    "\n",
    "        rf = RandomForestClassifier(**params, n_jobs=-1).fit(final_X, final_y)\n",
    "\n",
    "        # Get predicted probabilities for the positive class on the training set\n",
    "        prob_positive_class_train = rf.predict_proba(final_X)[:, 1]\n",
    "\n",
    "        # Find the best threshold using training set\n",
    "        best_threshold = find_best_threshold(prob_positive_class_train, final_y)\n",
    "\n",
    "        # Prediction of probabilities on the test set\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            transformed_X_test = final_x_transformer.transform(pred)\n",
    "            prob_positive_class_test = rf.predict_proba(transformed_X_test)[:, 1]\n",
    "        else:\n",
    "            prob_positive_class_test = rf.predict_proba(pred)[:, 1]\n",
    "\n",
    "        # Apply the custom threshold to make final binary prediction\n",
    "        final_prediction = np.where(prob_positive_class_test > best_threshold, 1, 0)\n",
    "\n",
    "        prediction = final_prediction[0]\n",
    "        # Assuming you are interested in the first prediction if 'pred' contains multiple samples\n",
    "\n",
    "    elif final_model == 'XGBoost':\n",
    "        print('xgb')\n",
    "        best_score = 0\n",
    "        tracker = 0\n",
    "#         while best_score < final_model_cv_score:\n",
    "        params, best_score = perform_hyper_param_tuning_bayes_xgb(final_X, final_y, randint(0, 20000))\n",
    "#             if tracker == 2:\n",
    "#                 break\n",
    "#             tracker += 1\n",
    "\n",
    "        xgb = XGBClassifier(**params).fit(final_X, final_y)\n",
    "\n",
    "        # Get predicted probabilities for the positive class on the training set\n",
    "        prob_positive_class_train = xgb.predict_proba(final_X)[:, 1]\n",
    "\n",
    "        # Find the best threshold using training set\n",
    "        best_threshold = find_best_threshold(prob_positive_class_train, final_y)\n",
    "\n",
    "        # Prediction of probabilities on the test set\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            transformed_X_test = final_x_transformer.transform(pred)\n",
    "            prob_positive_class_test = xgb.predict_proba(transformed_X_test)[:, 1]\n",
    "        else:\n",
    "            prob_positive_class_test = xgb.predict_proba(pred)[:, 1]\n",
    "\n",
    "        # Apply the custom threshold to make final binary prediction\n",
    "        final_prediction = np.where(prob_positive_class_test > best_threshold, 1, 0)\n",
    "\n",
    "        prediction = final_prediction[0]\n",
    "\n",
    "    elif final_model == 'CatBoost': \n",
    "        best_score =0 \n",
    "        tracker = 0\n",
    "        while best_score <final_model_cv_score:\n",
    "            params, best_score = perform_hyper_param_tuning_bayes_catboost(final_X,final_y,randint(0,20000))\n",
    "            if tracker ==2:\n",
    "                break\n",
    "            tracker+=1\n",
    "\n",
    "        cb = CatBoostClassifier(**params, verbose=False).fit(final_X,final_y)\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            prediction = cb.predict(final_x_transformer.transform(pred))\n",
    "    elif final_model == 'LightGBM':\n",
    "        best_score = 0\n",
    "        tracker = 0\n",
    "        final_model_cv_score=.01\n",
    "        while best_score < final_model_cv_score:\n",
    "            params, best_score = perform_hyper_param_tuning_bayes_lgbm(final_X, final_y, randint(0, 20000))\n",
    "            if tracker == 2:\n",
    "                break\n",
    "            tracker += 1\n",
    "\n",
    "        lgbm = LGBMClassifier(**params, verbose=0).fit(final_X, final_y)\n",
    "\n",
    "        # Get predicted probabilities for the positive class on the training set\n",
    "        prob_positive_class_train = lgbm.predict_proba(final_X)[:, 1]\n",
    "\n",
    "        # Find the best threshold using training set\n",
    "        best_threshold = find_best_threshold(prob_positive_class_train, final_y)\n",
    "\n",
    "        # Prediction of probabilities on the test set\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            transformed_X_test = final_x_transformer.transform(pred)\n",
    "            prob_positive_class_test = lgbm.predict_proba(transformed_X_test)[:, 1]\n",
    "        else:\n",
    "            prob_positive_class_test = lgbm.predict_proba(pred)[:, 1]\n",
    "\n",
    "        # Apply the custom threshold to make final binary prediction\n",
    "        final_prediction = np.where(prob_positive_class_test > best_threshold, 1, 0)\n",
    "\n",
    "        # Assuming you are interested in the first prediction if 'pred' contains multiple samples\n",
    "        prediction = final_prediction[0]\n",
    "        # Assuming you are interested in the first prediction if 'pred' contains multiple samples\n",
    "\n",
    "    elif final_model == 'SVM': \n",
    "        print('its and svm')\n",
    "        best_score =0 \n",
    "        tracker = 0\n",
    "#         while best_score <final_model_cv_score:\n",
    "        params, best_score = perform_hyper_param_tuning_bayes_svc(final_X,final_y,randint(0,20000))\n",
    "#             if tracker ==2:\n",
    "#                 break\n",
    "#             tracker+=1\n",
    "        svm = SVC(**params, probability=True, verbose=False).fit(final_X, final_y)\n",
    "        prob_positive_class = svm.predict_proba(final_X)[:, 1]\n",
    "\n",
    "        # Find the best threshold\n",
    "        best_threshold = find_best_threshold(prob_positive_class, final_y)\n",
    "\n",
    "        # Prediction of probabilities\n",
    "        # Assuming final_X_test is your test set features\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            transformed_X_test = final_x_transformer.transform(pred)\n",
    "            prob_positive_class = svm.predict_proba(transformed_X_test)[:, 1]\n",
    "        else:\n",
    "            prob_positive_class = svm.predict_proba(pred)[:, 1]\n",
    "        prob_positive_class_test = prob_positive_class\n",
    "        prediction = int(prob_positive_class[0]>best_threshold)\n",
    "\n",
    "    elif final_model == 'KNN':\n",
    "        best_score = 0\n",
    "        tracker = 0\n",
    "#         while best_score < final_model_cv_score:\n",
    "        params, best_score = perform_hyper_param_tuning_knn(final_X, final_y, randint(0, 20000))\n",
    "\n",
    "#             # Map indices to actual values for 'metric' and 'weights'\n",
    "#             params['metric'] = ['euclidean', 'manhattan', 'minkowski'][params['metric']]\n",
    "#             params['weights'] = ['uniform', 'distance'][params['weights']]\n",
    "\n",
    "#             if tracker == 2:\n",
    "#                 break\n",
    "#             tracker += 1\n",
    "\n",
    "        knn = KNeighborsClassifier(**params).fit(final_X, final_y)\n",
    "\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            prediction = knn.predict(final_x_transformer.transform(pred))\n",
    "        prob_positive_class_test = prediction[0]\n",
    "    elif final_model == 'Regularized Neural Network':\n",
    "        best_score =0 \n",
    "        tracker = 0\n",
    "        while best_score <final_model_cv_score:\n",
    "            params, best_score = perform_hyper_param_tuning_bayes_mlp(final_X,final_y,randint(0,20000))\n",
    "            if tracker ==2:\n",
    "                break\n",
    "            tracker+=1\n",
    "\n",
    "        mlp = MLPClassifier(**params, verbose=False).fit(final_X,final_y)\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            prediction = mlp.predict(final_x_transformer.transform(pred))\n",
    "    elif final_model == 'Bayesian':\n",
    "        print('nb')\n",
    "        best_score = 0\n",
    "        tracker = 0\n",
    "        while best_score < final_model_cv_score:\n",
    "            params, best_score = perform_hyper_param_tuning_bayes_nb(final_X, final_y, randint(0, 20000))\n",
    "            if tracker == 2:\n",
    "                break\n",
    "            tracker += 1\n",
    "\n",
    "        nb = GaussianNB(**params).fit(final_X, final_y)\n",
    "        loo = LeaveOneOut()\n",
    "\n",
    "        # Get predicted probabilities for the positive class on the training set\n",
    "        prob_positive_class_train = nb.predict_proba(final_X)[:, 1]\n",
    "\n",
    "        # Find the best threshold using training set\n",
    "        best_threshold = find_best_threshold(prob_positive_class_train, final_y)\n",
    "\n",
    "        # Cross-validation for model accuracy\n",
    "        scores = cross_val_score(nb, final_X, final_y, cv=loo, n_jobs=-1)\n",
    "\n",
    "        # Prediction of probabilities on the test set\n",
    "        if 'SelectFromModel' in str(final_x_transformer) or 'PCA' in str(final_x_transformer):\n",
    "            transformed_X_test = final_x_transformer.transform(pred)\n",
    "            prob_positive_class_test = nb.predict_proba(transformed_X_test)[:, 1]\n",
    "        else:\n",
    "            prob_positive_class_test = nb.predict_proba(pred)[:, 1]\n",
    "\n",
    "        # Apply the custom threshold to make final binary prediction\n",
    "        final_prediction = np.where(prob_positive_class_test > best_threshold, 1, 0)\n",
    "\n",
    "        prediction = final_prediction[0]\n",
    "        # Assuming you are interested in the first prediction if 'pred' contains multiple samples\n",
    "    return prediction, prob_positive_class_test, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b1b1833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model\n",
    "final_model_cv_score \n",
    "final_model_score \n",
    "final_scoring_type \n",
    "final_dataset \n",
    "type_of_data \n",
    "final_x_transformer\n",
    "base_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbc85b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model('203915',11.5,'MIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8aaa2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pd.read_csv('betr_current_pts_lines.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5c4a0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'localhost\\SQLEXPRESS'\n",
    "atabase = 'nba_game_data'\n",
    "sql = f'''\n",
    "SELECT distinct\n",
    "      [PLAYER]\n",
    "      ,[NICKNAME]\n",
    "      ,[PLAYER_SLUG]\n",
    "      ,[PLAYER_ID]\n",
    "  FROM [nba_game_data].[dbo].[CommonTeamRoster]\n",
    "'''\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';')\n",
    "cursor = cnxn.cursor()\n",
    "players = pd.read_sql(sql,cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5cf5df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['PLAYER_NAME'] = lines['PLAYER_NAME'].astype(str)\n",
    "lines['PLAYER_NAME'] = [x.strip() for x in lines['PLAYER_NAME']]\n",
    "lines['player_slug'] = [slugify(x) for x in lines['PLAYER_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d030d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.merge(players, left_on = 'player_slug', right_on='PLAYER_SLUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "695402ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['model_guess_over'] = ''\n",
    "lines['model__guess_proba_over'] = ''\n",
    "lines['model_score_over'] = ''\n",
    "\n",
    "lines['model_guess_under'] = ''\n",
    "lines['model__guess_proba_under'] = ''\n",
    "lines['model_score_under'] = ''\n",
    "\n",
    "lines['data_used'] = ''\n",
    "lines['model_type'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "412b7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e037c949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>OPP</th>\n",
       "      <th>PTS</th>\n",
       "      <th>player_slug</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>NICKNAME</th>\n",
       "      <th>PLAYER_SLUG</th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>model_guess_over</th>\n",
       "      <th>model__guess_proba_over</th>\n",
       "      <th>model_score_over</th>\n",
       "      <th>model_guess_under</th>\n",
       "      <th>model__guess_proba_under</th>\n",
       "      <th>model_score_under</th>\n",
       "      <th>data_used</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pascal Siakam</td>\n",
       "      <td>NYK</td>\n",
       "      <td>21.5</td>\n",
       "      <td>pascal-siakam</td>\n",
       "      <td>Pascal Siakam</td>\n",
       "      <td>Pascal</td>\n",
       "      <td>pascal-siakam</td>\n",
       "      <td>1627783</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tyrese Haliburton</td>\n",
       "      <td>NYK</td>\n",
       "      <td>15.5</td>\n",
       "      <td>tyrese-haliburton</td>\n",
       "      <td>Tyrese Haliburton</td>\n",
       "      <td>Tyrese</td>\n",
       "      <td>tyrese-haliburton</td>\n",
       "      <td>1630169</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Nesmith</td>\n",
       "      <td>NYK</td>\n",
       "      <td>14.5</td>\n",
       "      <td>aaron-nesmith</td>\n",
       "      <td>Aaron Nesmith</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>aaron-nesmith</td>\n",
       "      <td>1630174</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Myles Turner</td>\n",
       "      <td>NYK</td>\n",
       "      <td>16.5</td>\n",
       "      <td>myles-turner</td>\n",
       "      <td>Myles Turner</td>\n",
       "      <td>Myles</td>\n",
       "      <td>myles-turner</td>\n",
       "      <td>1626167</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jalen Brunson</td>\n",
       "      <td>IND</td>\n",
       "      <td>32.5</td>\n",
       "      <td>jalen-brunson</td>\n",
       "      <td>Jalen Brunson</td>\n",
       "      <td>Jalen</td>\n",
       "      <td>jalen-brunson</td>\n",
       "      <td>1628973</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Donte DiVincenzo</td>\n",
       "      <td>IND</td>\n",
       "      <td>18.5</td>\n",
       "      <td>donte-divincenzo</td>\n",
       "      <td>Donte DiVincenzo</td>\n",
       "      <td>Donte</td>\n",
       "      <td>donte-divincenzo</td>\n",
       "      <td>1628978</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Josh Hart</td>\n",
       "      <td>IND</td>\n",
       "      <td>11.5</td>\n",
       "      <td>josh-hart</td>\n",
       "      <td>Josh Hart</td>\n",
       "      <td>Josh</td>\n",
       "      <td>josh-hart</td>\n",
       "      <td>1628404</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Isaiah HartenStein</td>\n",
       "      <td>IND</td>\n",
       "      <td>9.5</td>\n",
       "      <td>isaiah-hartenstein</td>\n",
       "      <td>Isaiah Hartenstein</td>\n",
       "      <td>Isaiah</td>\n",
       "      <td>isaiah-hartenstein</td>\n",
       "      <td>1628392</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PLAYER_NAME  OPP   PTS         player_slug              PLAYER  \\\n",
       "0       Pascal Siakam  NYK  21.5       pascal-siakam       Pascal Siakam   \n",
       "1   Tyrese Haliburton  NYK  15.5   tyrese-haliburton   Tyrese Haliburton   \n",
       "2       Aaron Nesmith  NYK  14.5       aaron-nesmith       Aaron Nesmith   \n",
       "3        Myles Turner  NYK  16.5        myles-turner        Myles Turner   \n",
       "4       Jalen Brunson  IND  32.5       jalen-brunson       Jalen Brunson   \n",
       "5    Donte DiVincenzo  IND  18.5    donte-divincenzo    Donte DiVincenzo   \n",
       "6           Josh Hart  IND  11.5           josh-hart           Josh Hart   \n",
       "7  Isaiah HartenStein  IND   9.5  isaiah-hartenstein  Isaiah Hartenstein   \n",
       "\n",
       "  NICKNAME         PLAYER_SLUG PLAYER_ID model_guess_over  \\\n",
       "0   Pascal       pascal-siakam   1627783                    \n",
       "1   Tyrese   tyrese-haliburton   1630169                    \n",
       "2    Aaron       aaron-nesmith   1630174                    \n",
       "3    Myles        myles-turner   1626167                    \n",
       "4    Jalen       jalen-brunson   1628973                    \n",
       "5    Donte    donte-divincenzo   1628978                    \n",
       "6     Josh           josh-hart   1628404                    \n",
       "7   Isaiah  isaiah-hartenstein   1628392                    \n",
       "\n",
       "  model__guess_proba_over model_score_over model_guess_under  \\\n",
       "0                                                              \n",
       "1                                                              \n",
       "2                                                              \n",
       "3                                                              \n",
       "4                                                              \n",
       "5                                                              \n",
       "6                                                              \n",
       "7                                                              \n",
       "\n",
       "  model__guess_proba_under model_score_under data_used model_type  \n",
       "0                                                                  \n",
       "1                                                                  \n",
       "2                                                                  \n",
       "3                                                                  \n",
       "4                                                                  \n",
       "5                                                                  \n",
       "6                                                                  \n",
       "7                                                                  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "390c53a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pascal Siakam 21.5 NYK\n",
      "23.5\n",
      "nb\n",
      "100%|█████████████████████████████████████████████| 350/350 [00:55<00:00,  6.34trial/s, best loss: -0.2682926829268293]\n",
      "[1.] 0.2682926829268293\n",
      "19.5\n",
      "dt\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:11<00:00,  8.34trial/s, best loss: -0.717391304347826]\n",
      "[0.73333333] 0.717391304347826\n",
      "Tyrese Haliburton 15.5 NYK\n",
      "17.5\n",
      "nb\n",
      "100%|█████████████████████████████████████████████| 350/350 [00:29<00:00, 12.02trial/s, best loss: -0.7272727272727273]\n",
      "[1.] 0.7272727272727273\n",
      "13.5\n",
      "nb\n",
      "100%|████████████████████████████████████████████| 350/350 [00:28<00:00, 12.19trial/s, best loss: -0.09090909090909091]\n",
      "[0.] 0.09090909090909091\n",
      "Aaron Nesmith 14.5 NYK\n",
      "16.5\n",
      "nb\n",
      "100%|████████████████████████████████████████████| 350/350 [00:50<00:00,  6.93trial/s, best loss: -0.08333333333333333]\n",
      "[1.] 0.08333333333333333\n",
      "12.5\n",
      "its and svm\n",
      "100%|█████████████████████████████████████████████| 150/150 [46:44<00:00, 18.70s/trial, best loss: -0.7195121951219512]\n",
      "[0.79052346] 0.7195121951219512\n",
      "Myles Turner 16.5 NYK\n",
      "18.5\n",
      "nb\n",
      "100%|████████████████████████████████████████████| 350/350 [00:51<00:00,  6.82trial/s, best loss: -0.26666666666666666]\n",
      "[1.] 0.26666666666666666\n",
      "14.5\n",
      "nb\n",
      "100%|████████████████████████████████████████████| 350/350 [00:50<00:00,  6.92trial/s, best loss: -0.23333333333333334]\n",
      "[0.] 0.23333333333333334\n",
      "Jalen Brunson 32.5 IND\n",
      "34.5\n",
      "nb\n",
      "100%|████████████████████████████████████████████| 350/350 [00:50<00:00,  6.89trial/s, best loss: -0.11666666666666667]\n",
      "[1.] 0.11666666666666667\n",
      "30.5\n",
      "its and svm\n",
      "100%|█████████████████████████████████████████████| 150/150 [00:25<00:00,  5.93trial/s, best loss: -0.8170731707317073]\n",
      "[0.81604782] 0.8170731707317073\n",
      "Donte DiVincenzo 18.5 IND\n",
      "20.5\n",
      "nb\n",
      "100%|███████████████████████████████████████████| 350/350 [00:37<00:00,  9.44trial/s, best loss: -0.044444444444444446]\n",
      "[0.] 0.044444444444444446\n",
      "16.5\n",
      "nb\n",
      "100%|█████████████████████████████████████████████| 350/350 [00:53<00:00,  6.50trial/s, best loss: -0.9024390243902439]\n",
      "[1.] 0.9024390243902439\n",
      "Josh Hart 11.5 IND\n",
      "13.5\n",
      "nb\n",
      "100%|████████████████████████████████████████████| 350/350 [00:39<00:00,  8.80trial/s, best loss: -0.06382978723404255]\n",
      "[0.] 0.06382978723404255\n",
      "9.5\n",
      "its and svm\n",
      "100%|█████████████████████████████████████████████| 150/150 [12:44<00:00,  5.10s/trial, best loss: -0.6595744680851063]\n",
      "[0.6482441] 0.6595744680851063\n",
      "Isaiah HartenStein 9.5 IND\n",
      "11.5\n",
      "nb\n",
      "100%|████████████████████████████████████████████| 350/350 [00:38<00:00,  8.98trial/s, best loss: -0.08695652173913043]\n",
      "[0.] 0.08695652173913043\n",
      "7.5\n",
      "its and svm\n",
      "100%|█████████████████████████████████████████████| 150/150 [00:25<00:00,  5.93trial/s, best loss: -0.7439024390243902]\n",
      "[0.66863802] 0.7439024390243902\n"
     ]
    }
   ],
   "source": [
    "# results = pd.DataFrame()\n",
    "for index, row in lines.iterrows():\n",
    "    print(str(row['PLAYER_NAME']),row['PTS'],str(row['OPP']))\n",
    "    try:\n",
    "        line = row['PTS'] + 2\n",
    "        print(line)\n",
    "        predict_over, prectic_proba_over, model_score_over = model(str(row['PLAYER_ID']),line,str(row['OPP']))\n",
    "        print(prectic_proba_over,model_score_over)\n",
    "        \n",
    "        line = row['PTS']-2\n",
    "        print(line)\n",
    "        predict_under, prectic_proba_under, model_score_under = model(str(row['PLAYER_ID']),line,str(row['OPP']),'under')\n",
    "        print(prectic_proba_under,model_score_under)\n",
    "        \n",
    "        if (prectic_proba_over > .5 and model_score_over > .75) or (prectic_proba_under > .5 and model_score_under > .6):\n",
    "            lines.iloc[index,8] = predict_over\n",
    "            lines.iloc[index,9] = prectic_proba_over[0]\n",
    "            lines.iloc[index,10] = model_score_over\n",
    "\n",
    "            lines.iloc[index,11] = predict_under\n",
    "            lines.iloc[index,12] = prectic_proba_under[0]\n",
    "            lines.iloc[index,13] = model_score_under\n",
    "\n",
    "            lines.iloc[index,14] = final_dataset\n",
    "            lines.iloc[index,15]=str(final_model)\n",
    "\n",
    "    \n",
    "    except:\n",
    "        print(row['PLAYER_NAME'], 'failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c30f038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>OPP</th>\n",
       "      <th>PTS</th>\n",
       "      <th>player_slug</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>NICKNAME</th>\n",
       "      <th>PLAYER_SLUG</th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>model_guess_over</th>\n",
       "      <th>model__guess_proba_over</th>\n",
       "      <th>model_score_over</th>\n",
       "      <th>model_guess_under</th>\n",
       "      <th>model__guess_proba_under</th>\n",
       "      <th>model_score_under</th>\n",
       "      <th>data_used</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pascal Siakam</td>\n",
       "      <td>NYK</td>\n",
       "      <td>21.5</td>\n",
       "      <td>pascal-siakam</td>\n",
       "      <td>Pascal Siakam</td>\n",
       "      <td>Pascal</td>\n",
       "      <td>pascal-siakam</td>\n",
       "      <td>1627783</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>season</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tyrese Haliburton</td>\n",
       "      <td>NYK</td>\n",
       "      <td>15.5</td>\n",
       "      <td>tyrese-haliburton</td>\n",
       "      <td>Tyrese Haliburton</td>\n",
       "      <td>Tyrese</td>\n",
       "      <td>tyrese-haliburton</td>\n",
       "      <td>1630169</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Nesmith</td>\n",
       "      <td>NYK</td>\n",
       "      <td>14.5</td>\n",
       "      <td>aaron-nesmith</td>\n",
       "      <td>Aaron Nesmith</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>aaron-nesmith</td>\n",
       "      <td>1630174</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790523</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>buffer</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Myles Turner</td>\n",
       "      <td>NYK</td>\n",
       "      <td>16.5</td>\n",
       "      <td>myles-turner</td>\n",
       "      <td>Myles Turner</td>\n",
       "      <td>Myles</td>\n",
       "      <td>myles-turner</td>\n",
       "      <td>1626167</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jalen Brunson</td>\n",
       "      <td>IND</td>\n",
       "      <td>32.5</td>\n",
       "      <td>jalen-brunson</td>\n",
       "      <td>Jalen Brunson</td>\n",
       "      <td>Jalen</td>\n",
       "      <td>jalen-brunson</td>\n",
       "      <td>1628973</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.816048</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>buffer</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Donte DiVincenzo</td>\n",
       "      <td>IND</td>\n",
       "      <td>18.5</td>\n",
       "      <td>donte-divincenzo</td>\n",
       "      <td>Donte DiVincenzo</td>\n",
       "      <td>Donte</td>\n",
       "      <td>donte-divincenzo</td>\n",
       "      <td>1628978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>buffer</td>\n",
       "      <td>Bayesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Josh Hart</td>\n",
       "      <td>IND</td>\n",
       "      <td>11.5</td>\n",
       "      <td>josh-hart</td>\n",
       "      <td>Josh Hart</td>\n",
       "      <td>Josh</td>\n",
       "      <td>josh-hart</td>\n",
       "      <td>1628404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648244</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>season</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Isaiah HartenStein</td>\n",
       "      <td>IND</td>\n",
       "      <td>9.5</td>\n",
       "      <td>isaiah-hartenstein</td>\n",
       "      <td>Isaiah Hartenstein</td>\n",
       "      <td>Isaiah</td>\n",
       "      <td>isaiah-hartenstein</td>\n",
       "      <td>1628392</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0</td>\n",
       "      <td>0.668638</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>buffer</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PLAYER_NAME  OPP   PTS         player_slug              PLAYER  \\\n",
       "0       Pascal Siakam  NYK  21.5       pascal-siakam       Pascal Siakam   \n",
       "1   Tyrese Haliburton  NYK  15.5   tyrese-haliburton   Tyrese Haliburton   \n",
       "2       Aaron Nesmith  NYK  14.5       aaron-nesmith       Aaron Nesmith   \n",
       "3        Myles Turner  NYK  16.5        myles-turner        Myles Turner   \n",
       "4       Jalen Brunson  IND  32.5       jalen-brunson       Jalen Brunson   \n",
       "5    Donte DiVincenzo  IND  18.5    donte-divincenzo    Donte DiVincenzo   \n",
       "6           Josh Hart  IND  11.5           josh-hart           Josh Hart   \n",
       "7  Isaiah HartenStein  IND   9.5  isaiah-hartenstein  Isaiah Hartenstein   \n",
       "\n",
       "  NICKNAME         PLAYER_SLUG PLAYER_ID model_guess_over  \\\n",
       "0   Pascal       pascal-siakam   1627783                1   \n",
       "1   Tyrese   tyrese-haliburton   1630169                    \n",
       "2    Aaron       aaron-nesmith   1630174                1   \n",
       "3    Myles        myles-turner   1626167                    \n",
       "4    Jalen       jalen-brunson   1628973                1   \n",
       "5    Donte    donte-divincenzo   1628978                0   \n",
       "6     Josh           josh-hart   1628404                0   \n",
       "7   Isaiah  isaiah-hartenstein   1628392                0   \n",
       "\n",
       "  model__guess_proba_over model_score_over model_guess_under  \\\n",
       "0                     1.0         0.268293                 1   \n",
       "1                                                              \n",
       "2                     1.0         0.083333                 1   \n",
       "3                                                              \n",
       "4                     1.0         0.116667                 1   \n",
       "5                     0.0         0.044444                 1   \n",
       "6                     0.0          0.06383                 1   \n",
       "7                     0.0         0.086957                 0   \n",
       "\n",
       "  model__guess_proba_under model_score_under data_used     model_type  \n",
       "0                 0.733333          0.717391    season  Decision Tree  \n",
       "1                                                                      \n",
       "2                 0.790523          0.719512    buffer            SVM  \n",
       "3                                                                      \n",
       "4                 0.816048          0.817073    buffer            SVM  \n",
       "5                      1.0          0.902439    buffer       Bayesian  \n",
       "6                 0.648244          0.659574    season            SVM  \n",
       "7                 0.668638          0.743902    buffer            SVM  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e63d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.loc[lines['model_score_over']!='']\n",
    "output = lines[['PLAYER_NAME','PTS','model_guess_over','model__guess_proba_over','model_score_over','model_guess_under','model__guess_proba_under','model_score_under','model_type','data_used']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "930e0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.sort_values(by='model_score_over', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8218415c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>PTS</th>\n",
       "      <th>model_guess_over</th>\n",
       "      <th>model__guess_proba_over</th>\n",
       "      <th>model_score_over</th>\n",
       "      <th>model_guess_under</th>\n",
       "      <th>model__guess_proba_under</th>\n",
       "      <th>model_score_under</th>\n",
       "      <th>model_type</th>\n",
       "      <th>data_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pascal Siakam</td>\n",
       "      <td>21.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jalen Brunson</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.816048</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>SVM</td>\n",
       "      <td>buffer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Isaiah HartenStein</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0</td>\n",
       "      <td>0.668638</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>SVM</td>\n",
       "      <td>buffer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Nesmith</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790523</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>SVM</td>\n",
       "      <td>buffer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Josh Hart</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648244</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>SVM</td>\n",
       "      <td>season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Donte DiVincenzo</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>Bayesian</td>\n",
       "      <td>buffer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PLAYER_NAME   PTS model_guess_over model__guess_proba_over  \\\n",
       "0       Pascal Siakam  21.5                1                     1.0   \n",
       "4       Jalen Brunson  32.5                1                     1.0   \n",
       "7  Isaiah HartenStein   9.5                0                     0.0   \n",
       "2       Aaron Nesmith  14.5                1                     1.0   \n",
       "6           Josh Hart  11.5                0                     0.0   \n",
       "5    Donte DiVincenzo  18.5                0                     0.0   \n",
       "\n",
       "  model_score_over model_guess_under model__guess_proba_under  \\\n",
       "0         0.268293                 1                 0.733333   \n",
       "4         0.116667                 1                 0.816048   \n",
       "7         0.086957                 0                 0.668638   \n",
       "2         0.083333                 1                 0.790523   \n",
       "6          0.06383                 1                 0.648244   \n",
       "5         0.044444                 1                      1.0   \n",
       "\n",
       "  model_score_under     model_type data_used  \n",
       "0          0.717391  Decision Tree    season  \n",
       "4          0.817073            SVM    buffer  \n",
       "7          0.743902            SVM    buffer  \n",
       "2          0.719512            SVM    buffer  \n",
       "6          0.659574            SVM    season  \n",
       "5          0.902439       Bayesian    buffer  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ff57a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7828b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.to_csv('model_outputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65bb1996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent successfully!\n"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "def send_email(subject, to_email,df):\n",
    "    # Gmail account credentials\n",
    "    gmail_user = 'bobbys.daily.lines@gmail.com'  # Your email\n",
    "    gmail_app_password = 'zytx hudf gwky pdht'  # Your app password\n",
    "\n",
    "     # Convert DataFrame to HTML with advanced styling\n",
    "    styled_df = df.style.set_properties(**{\n",
    "        'border-color': 'black',\n",
    "        'border-width': '1px',\n",
    "        'text-align': 'center'\n",
    "    }).set_table_styles([\n",
    "        {'selector': 'th',\n",
    "         'props': [('background-color', '#4CAF50'),\n",
    "                   ('color', 'white'),\n",
    "                   ('padding', '12px')]}\n",
    "    ]).set_table_attributes('style=\"width:100%;border-collapse:collapse;\"').render()\n",
    "\n",
    "    html = f\"\"\"\\\n",
    "    <html>\n",
    "      <head>\n",
    "        <style>\n",
    "          body {{\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            background-color: #f3f3f3;\n",
    "            color: #333;\n",
    "            line-height: 1.6;\n",
    "          }}\n",
    "          .container {{\n",
    "            width: 95%;\n",
    "            margin: auto;\n",
    "            overflow: hidden;\n",
    "            padding: 20px 0;\n",
    "          }}\n",
    "          h1 {{\n",
    "            font-size: 2.5em;\n",
    "            margin-bottom: 10px;\n",
    "          }}\n",
    "          p {{\n",
    "            font-size: 1.1em;\n",
    "          }}\n",
    "          .table-responsive {{\n",
    "            overflow-x: auto;\n",
    "          }}\n",
    "          table {{\n",
    "            width: 100%;\n",
    "            margin-top: 20px;\n",
    "            border-collapse: collapse;\n",
    "          }}\n",
    "          th, td {{\n",
    "            padding: 10px;\n",
    "            text-align: center;\n",
    "            border: 1px solid black;\n",
    "          }}\n",
    "          th {{\n",
    "            background-color: #4CAF50;\n",
    "            color: white;\n",
    "          }}\n",
    "          tr:nth-child(even) {{\n",
    "            background-color: #f2f2f2;\n",
    "          }}\n",
    "        </style>\n",
    "      </head>\n",
    "      <body>\n",
    "        <div class=\"container\">\n",
    "          <h1>Good Morning, Mr. Plourde</h1>\n",
    "          <p>Below are your daily picks for today's lines. Have a great day!</p>\n",
    "          <div class=\"table-responsive\">\n",
    "            {styled_df}\n",
    "          </div>\n",
    "        </div>\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Email content setup\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = gmail_user\n",
    "    msg['To'] = to_email\n",
    "    msg['Subject'] = subject\n",
    "\n",
    "    msg.attach(MIMEText(html, 'html'))\n",
    "    \n",
    "    # Sending email\n",
    "    try:\n",
    "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        server.starttls()\n",
    "        server.login(gmail_user, gmail_app_password)\n",
    "        server.sendmail(gmail_user, to_email, msg.as_string())\n",
    "        server.quit()\n",
    "        print(\"Email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Usage\n",
    "send_email(f'Daily Line Picks for {str(date.today())}', 'bobby.plourde12@yahoo.com', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d67c3f0",
   "metadata": {},
   "source": [
    "# alittle more forgiving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d3623413",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pd.read_csv('betr_current_pts_lines.csv')\n",
    "\n",
    "server = 'localhost\\SQLEXPRESS'\n",
    "atabase = 'nba_game_data'\n",
    "sql = f'''\n",
    "SELECT distinct\n",
    "      [PLAYER]\n",
    "      ,[NICKNAME]\n",
    "      ,[PLAYER_SLUG]\n",
    "      ,[PLAYER_ID]\n",
    "  FROM [nba_game_data].[dbo].[CommonTeamRoster]\n",
    "'''\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';')\n",
    "cursor = cnxn.cursor()\n",
    "players = pd.read_sql(sql,cnxn)\n",
    "\n",
    "lines['PLAYER_NAME'] = lines['PLAYER_NAME'].astype(str)\n",
    "lines['PLAYER_NAME'] = [x.strip() for x in lines['PLAYER_NAME']]\n",
    "lines['player_slug'] = [slugify(x) for x in lines['PLAYER_NAME']]\n",
    "\n",
    "lines = lines.merge(players, left_on = 'player_slug', right_on='PLAYER_SLUG')\n",
    "\n",
    "lines['model_guess_over'] = ''\n",
    "lines['model__guess_proba_over'] = ''\n",
    "lines['model_score_over'] = ''\n",
    "\n",
    "lines['model_guess_under'] = ''\n",
    "lines['model__guess_proba_under'] = ''\n",
    "lines['model_score_under'] = ''\n",
    "\n",
    "lines['data_used'] = ''\n",
    "lines['model_type'] = ''\n",
    "\n",
    "# lines['PTS'] = lines['PTS']+1\n",
    "\n",
    "lines = lines.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "79de5e77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pascal Siakam 21.5 NYK\n",
      "22.5\n",
      "nb\n",
      "100%|█████████████████████████████████████████████| 350/350 [00:54<00:00,  6.46trial/s, best loss: -0.4268292682926829]\n",
      "[0.] 0.4268292682926829\n",
      "20.5\n",
      "dt\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:12<00:00,  8.27trial/s, best loss: -0.7608695652173914]\n",
      "[0.] 0.7608695652173914\n",
      "Tyrese Haliburton 15.5 NYK\n",
      "16.5\n",
      "its and svm\n",
      "100%|█████████████████████████████████████████████| 150/150 [23:53<00:00,  9.55s/trial, best loss: -0.7878787878787878]\n",
      "[1.0000001e-07] 0.7878787878787878\n",
      "14.5\n",
      "dt\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:08<00:00, 12.05trial/s, best loss: -0.8787878787878788]\n",
      "[0.] 0.8787878787878788\n",
      "Aaron Nesmith 14.5 NYK\n",
      "15.5\n",
      "nb\n",
      "100%|████████████████████████████████████████████| 350/350 [00:50<00:00,  6.88trial/s, best loss: -0.11666666666666667]\n",
      "[1.] 0.11666666666666667\n",
      "13.5\n",
      "nb\n",
      "100%|█████████████████████████████████████████████| 350/350 [00:53<00:00,  6.54trial/s, best loss: -0.7804878048780488]\n",
      "[1.] 0.7804878048780488\n",
      "Myles Turner 16.5 NYK\n",
      "17.5\n",
      "xgb\n",
      "100%|████████████████████████████████████████████| 100/100 [02:17<00:00,  1.37s/trial, best loss: -0.31666666666666665]\n",
      "[0.5441066] 0.31666666666666665\n",
      "15.5\n",
      "xgb\n",
      "100%|████████████████████████████████████████████| 100/100 [01:19<00:00,  1.25trial/s, best loss: -0.30434782608695654]\n",
      "[0.8881494] 0.30434782608695654\n",
      "Jalen Brunson 32.5 IND\n",
      "33.5\n",
      "dt\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:14<00:00,  6.71trial/s, best loss: -0.9666666666666667]\n",
      "[0.11111111] 0.9666666666666667\n",
      "31.5\n",
      "its and svm\n",
      "100%|█████████████████████████████████████████████| 150/150 [00:25<00:00,  5.89trial/s, best loss: -0.8536585365853658]\n",
      "[1.] 0.8536585365853658\n",
      "Donte DiVincenzo 18.5 IND\n",
      "19.5\n",
      "xgb\n",
      "100%|███████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: -0.044444444444444446]\n",
      "[0.00692173] 0.044444444444444446\n",
      "17.5\n",
      "nb\n",
      "100%|█████████████████████████████████████████████| 350/350 [00:53<00:00,  6.49trial/s, best loss: -0.9146341463414634]\n",
      "[1.] 0.9146341463414634\n",
      "Josh Hart 11.5 IND\n",
      "12.5\n",
      "dt\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:16<00:00,  6.21trial/s, best loss: -0.8414634146341463]\n",
      "[0.08333333] 0.8414634146341463\n",
      "10.5\n",
      "nb\n",
      "100%|██████████████████████████████████████████████| 350/350 [00:39<00:00,  8.79trial/s, best loss: -0.851063829787234]\n",
      "[1.] 0.851063829787234\n",
      "Isaiah HartenStein 9.5 IND\n",
      "10.5\n",
      "dt\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:11<00:00,  8.49trial/s, best loss: -0.9130434782608695]\n",
      "[0.0952381] 0.9130434782608695\n",
      "8.5\n",
      "its and svm\n",
      "100%|█████████████████████████████████████████████| 150/150 [00:25<00:00,  5.81trial/s, best loss: -0.8292682926829268]\n",
      "[0.83114495] 0.8292682926829268\n"
     ]
    }
   ],
   "source": [
    "# results = pd.DataFrame()\n",
    "for index, row in lines.iterrows():\n",
    "    print(str(row['PLAYER_NAME']),row['PTS'],str(row['OPP']))\n",
    "    try:\n",
    "        line = row['PTS'] + 1\n",
    "        print(line)\n",
    "        predict_over, prectic_proba_over, model_score_over = model(str(row['PLAYER_ID']),line,str(row['OPP']))\n",
    "        print(prectic_proba_over,model_score_over)\n",
    "        \n",
    "        line = row['PTS']-1\n",
    "        print(line)\n",
    "        predict_under, prectic_proba_under, model_score_under = model(str(row['PLAYER_ID']),line,str(row['OPP']),'under')\n",
    "        print(prectic_proba_under,model_score_under)\n",
    "        \n",
    "        if (prectic_proba_over > .5 and model_score_over > .75) or (prectic_proba_under > .5 and model_score_under > .6):\n",
    "            lines.iloc[index,8] = predict_over\n",
    "            lines.iloc[index,9] = prectic_proba_over[0]\n",
    "            lines.iloc[index,10] = model_score_over\n",
    "\n",
    "            lines.iloc[index,11] = predict_under\n",
    "            lines.iloc[index,12] = prectic_proba_under[0]\n",
    "            lines.iloc[index,13] = model_score_under\n",
    "\n",
    "            lines.iloc[index,14] = final_dataset\n",
    "            lines.iloc[index,15]=str(final_model)\n",
    "\n",
    "    \n",
    "    except:\n",
    "        print(row['PLAYER_NAME'], 'failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "483cac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.loc[lines['model_score_over']!='']\n",
    "output = lines[['PLAYER_NAME','PTS','model_guess_over','model__guess_proba_over','model_score_over','model_guess_under','model__guess_proba_under','model_score_under','model_type','data_used']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "53adc741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent successfully!\n"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "def send_email(subject, to_email,df):\n",
    "    # Gmail account credentials\n",
    "    gmail_user = 'bobbys.daily.lines@gmail.com'  # Your email\n",
    "    gmail_app_password = 'zytx hudf gwky pdht'  # Your app password\n",
    "\n",
    "     # Convert DataFrame to HTML with advanced styling\n",
    "    styled_df = df.style.set_properties(**{\n",
    "        'border-color': 'black',\n",
    "        'border-width': '1px',\n",
    "        'text-align': 'center'\n",
    "    }).set_table_styles([\n",
    "        {'selector': 'th',\n",
    "         'props': [('background-color', '#4CAF50'),\n",
    "                   ('color', 'white'),\n",
    "                   ('padding', '12px')]}\n",
    "    ]).set_table_attributes('style=\"width:100%;border-collapse:collapse;\"').render()\n",
    "\n",
    "    html = f\"\"\"\\\n",
    "    <html>\n",
    "      <head>\n",
    "        <style>\n",
    "          body {{\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            background-color: #f3f3f3;\n",
    "            color: #333;\n",
    "            line-height: 1.6;\n",
    "          }}\n",
    "          .container {{\n",
    "            width: 95%;\n",
    "            margin: auto;\n",
    "            overflow: hidden;\n",
    "            padding: 20px 0;\n",
    "          }}\n",
    "          h1 {{\n",
    "            font-size: 2.5em;\n",
    "            margin-bottom: 10px;\n",
    "          }}\n",
    "          p {{\n",
    "            font-size: 1.1em;\n",
    "          }}\n",
    "          .table-responsive {{\n",
    "            overflow-x: auto;\n",
    "          }}\n",
    "          table {{\n",
    "            width: 100%;\n",
    "            margin-top: 20px;\n",
    "            border-collapse: collapse;\n",
    "          }}\n",
    "          th, td {{\n",
    "            padding: 10px;\n",
    "            text-align: center;\n",
    "            border: 1px solid black;\n",
    "          }}\n",
    "          th {{\n",
    "            background-color: #4CAF50;\n",
    "            color: white;\n",
    "          }}\n",
    "          tr:nth-child(even) {{\n",
    "            background-color: #f2f2f2;\n",
    "          }}\n",
    "        </style>\n",
    "      </head>\n",
    "      <body>\n",
    "        <div class=\"container\">\n",
    "          <h1>Good Morning, Mr. Plourde</h1>\n",
    "          <p>Below are your daily picks for today's lines. Have a great day!</p>\n",
    "          <div class=\"table-responsive\">\n",
    "            {styled_df}\n",
    "          </div>\n",
    "        </div>\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Email content setup\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = gmail_user\n",
    "    msg['To'] = to_email\n",
    "    msg['Subject'] = subject\n",
    "\n",
    "    msg.attach(MIMEText(html, 'html'))\n",
    "    \n",
    "    # Sending email\n",
    "    try:\n",
    "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        server.starttls()\n",
    "        server.login(gmail_user, gmail_app_password)\n",
    "        server.sendmail(gmail_user, to_email, msg.as_string())\n",
    "        server.quit()\n",
    "        print(\"Email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Usage\n",
    "send_email(f'Daily Line Picks for {str(date.today())} (Non-Picky)', 'bobby.plourde12@yahoo.com', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b545ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(30)\n",
    "# This command will put the computer to sleep in Windows\n",
    "os.system(\"rundll32.exe powrprof.dll,SetSuspendState 0,1,0\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
