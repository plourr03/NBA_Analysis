{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88ce60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pyodbc\n",
    "from slugify import slugify\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score,accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from utils import PyroBayesianLogisticRegression, KFoldCrossValidationBobby,send_email \n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_value = 42\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "\n",
    "\n",
    "# Note: For TensorFlow 2.x, you may not need to set up a session as shown above. `tf.random.set_seed(seed_value)` is often sufficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e933838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencode_features(data, num_features=10):\n",
    "    # Preprocess data: Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "    # Dimensionality specifics\n",
    "    input_dim = data_scaled.shape[1]\n",
    "    encoding_dim = num_features\n",
    "\n",
    "    # Building the autoencoder\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "    # Encoder model\n",
    "    encoder = Model(input_layer, encoded)\n",
    "\n",
    "    # Compile autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "    # Configure early stopping\n",
    "    early_stopping = EarlyStopping(monitor='loss', min_delta=0.00001, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "    # Train the autoencoder\n",
    "    autoencoder.fit(data_scaled, data_scaled, epochs=5000, batch_size=256, shuffle=True, verbose=0, callbacks=[early_stopping], use_multiprocessing=True)\n",
    "\n",
    "    # Encode the data\n",
    "    encoded_data = encoder.predict(data_scaled, verbose=False, use_multiprocessing=True)\n",
    "\n",
    "    return encoded_data, encoder, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d602290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\bobby\\Downloads\\rw-sleeper-predictions-2024-03-19 (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1be390fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['line_Type'] = ''\n",
    "for i, row in df.iterrows():\n",
    "    if row['Market Name'] == 'Rebounds':\n",
    "        df.loc[i,'line_Type'] ='REB'\n",
    "    elif row['Market Name'] == '3PT Made':\n",
    "        df.loc[i,'line_Type'] ='FG3M'\n",
    "    elif row['Market Name'] == 'Assists':\n",
    "        df.loc[i,'line_Type'] ='AST'\n",
    "    elif row['Market Name'] == 'Blocks':\n",
    "        df.loc[i,'line_Type'] ='BLK'\n",
    "    elif row['Market Name'] == 'PTS+REB+AST':\n",
    "        df.loc[i,'line_Type'] ='PTS+REB+AST'\n",
    "    elif row['Market Name'] == 'Turnovers':\n",
    "        df.loc[i,'line_Type'] ='TOV'\n",
    "    elif row['Market Name'] == 'Points':\n",
    "        df.loc[i,'line_Type'] ='PTS'\n",
    "    elif row['Market Name'] == 'Steals':\n",
    "        df.loc[i,'line_Type'] ='STL'\n",
    "        \n",
    "df['Opponent'] = df['Opponent'].apply(lambda x: x.replace('@','').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0b17e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "# Slugify player names for both DataFrames\n",
    "df['Player_Slug'] = df['Player'].apply(slugify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec059bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'localhost\\SQLEXPRESS'\n",
    "database = 'nba_game_data'\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';')\n",
    "cursor = cnxn.cursor()\n",
    "sql = \"\"\"\n",
    "SELECT distinct\n",
    "      pgl.[PLAYER_NAME]\n",
    "      ,pgl.PLAYER_ID\n",
    "\n",
    "  FROM [nba_game_data].[dbo].[PlayerGameLogs] pgl\n",
    "  LEFT OUTER JOIN [nba_game_data].[dbo].[player_clustering] pc\n",
    "   on\n",
    "    cast(pgl.PLAYER_ID as int) = cast(pc.PLAYER_ID as int)\n",
    "  where yearSeason = 2024\n",
    "  \"\"\"\n",
    "players = pd.read_sql(sql,cnxn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59b9b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "players['Player_Slug'] = players['PLAYER_NAME'].apply(slugify)\n",
    "df = pd.merge(df, players, how='left', left_on = ['Player_Slug'],right_on=['Player_Slug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee1239a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset='PLAYER_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0822addd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      BKN\n",
       "1      BKN\n",
       "2      BKN\n",
       "3      ORL\n",
       "4      SAS\n",
       "      ... \n",
       "153    BKN\n",
       "154    MIN\n",
       "155    SAS\n",
       "156    CHA\n",
       "157    BKN\n",
       "Name: Team, Length: 142, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "290e6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = df[['PLAYER_ID','line_Type','Line','Opponent','PLAYER_NAME','Team']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37906cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['PLAYER_ID']=lines['PLAYER_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "582828eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>line_Type</th>\n",
       "      <th>Line</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1627827</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NOP</td>\n",
       "      <td>Dorian Finney-Smith</td>\n",
       "      <td>BKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1627827</td>\n",
       "      <td>PTS</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NOP</td>\n",
       "      <td>Dorian Finney-Smith</td>\n",
       "      <td>BKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203471</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>22.5</td>\n",
       "      <td>NOP</td>\n",
       "      <td>Dennis Schroder</td>\n",
       "      <td>BKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1630591</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>16.5</td>\n",
       "      <td>CHA</td>\n",
       "      <td>Jalen Suggs</td>\n",
       "      <td>ORL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1630200</td>\n",
       "      <td>REB</td>\n",
       "      <td>3.5</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Tre Jones</td>\n",
       "      <td>SAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1627827</td>\n",
       "      <td>BLK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NOP</td>\n",
       "      <td>Dorian Finney-Smith</td>\n",
       "      <td>BKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1630162</td>\n",
       "      <td>AST</td>\n",
       "      <td>4.5</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Anthony Edwards</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1641705</td>\n",
       "      <td>TOV</td>\n",
       "      <td>3.5</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Victor Wembanyama</td>\n",
       "      <td>SAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1628970</td>\n",
       "      <td>PTS</td>\n",
       "      <td>20.5</td>\n",
       "      <td>ORL</td>\n",
       "      <td>Miles Bridges</td>\n",
       "      <td>CHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1627827</td>\n",
       "      <td>FG3M</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NOP</td>\n",
       "      <td>Dorian Finney-Smith</td>\n",
       "      <td>BKN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PLAYER_ID    line_Type  Line Opponent          PLAYER_NAME Team\n",
       "0      1627827  PTS+REB+AST  14.5      NOP  Dorian Finney-Smith  BKN\n",
       "1      1627827          PTS   7.5      NOP  Dorian Finney-Smith  BKN\n",
       "2       203471  PTS+REB+AST  22.5      NOP      Dennis Schroder  BKN\n",
       "3      1630591  PTS+REB+AST  16.5      CHA          Jalen Suggs  ORL\n",
       "4      1630200          REB   3.5      DAL            Tre Jones  SAS\n",
       "..         ...          ...   ...      ...                  ...  ...\n",
       "153    1627827          BLK   0.5      NOP  Dorian Finney-Smith  BKN\n",
       "154    1630162          AST   4.5      DEN      Anthony Edwards  MIN\n",
       "155    1641705          TOV   3.5      DAL    Victor Wembanyama  SAS\n",
       "156    1628970          PTS  20.5      ORL        Miles Bridges  CHA\n",
       "157    1627827         FG3M   1.5      NOP  Dorian Finney-Smith  BKN\n",
       "\n",
       "[142 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "baeb948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, server, database):\n",
    "    conn_str = 'DRIVER={SQL Server};SERVER=' + server + ';DATABASE=' + database + ';'\n",
    "    with pyodbc.connect(conn_str) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        query = \"EXEC seasonPtsDataSet @pts_thresh = ?, @player_id = ?, @line_type = ?\"\n",
    "        params = (row['Line'], int(row['PLAYER_ID']), str(row['line_Type']))\n",
    "        cursor.execute(query, params)\n",
    "        results = cursor.fetchall()\n",
    "        if results:\n",
    "            temp_df = pd.DataFrame.from_records(results, columns=[column[0] for column in cursor.description])\n",
    "            temp_df['GAME_DATE'] = pd.to_datetime(temp_df['GAME_DATE'])\n",
    "            temp_df['LineType'] = str(row['line_Type'])\n",
    "            # Filter where Date matches GAME_DATE\n",
    "            return temp_df\n",
    "        \n",
    "    return pd.DataFrame()  # Return an empty DataFrame if there are no results or an error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a1bb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute for each row in parallel\n",
    "def process_row_pred(row, server, database):\n",
    "    conn_str = 'DRIVER={SQL Server};SERVER=' + server + ';DATABASE=' + database + ';'\n",
    "    with pyodbc.connect(conn_str) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        query = \"EXEC seasonPtsDataSetPred @pts_thresh = ?, @player_id = ?, @line_type = ?, @opp = ?\"\n",
    "        params = (row['Line'], int(row['PLAYER_ID']), str(row['line_Type']), str(row['Opponent']))\n",
    "        cursor.execute(query, params)\n",
    "        results = cursor.fetchall()\n",
    "        if results:\n",
    "            temp_df = pd.DataFrame.from_records(results, columns=[column[0] for column in cursor.description])\n",
    "            temp_df['LineType'] = str(row['line_Type'])\n",
    "            return temp_df\n",
    "    return pd.DataFrame()  # Return an empty DataFrame if there are no results or an error occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = pd.DataFrame()\n",
    "# for index,row in lines.iterrows():\n",
    "#     try:\n",
    "data = process_row(row,server,database)\n",
    "data = data.sort_values(by='GAME_DATE').reset_index(drop=True).iloc[1:]\n",
    "\n",
    "data = data.drop(columns=['PLAYER_ID','GAME_DATE','LineType'])\n",
    "features = data.columns\n",
    "for column in data.columns:\n",
    "    # Check if the column is numeric, as median can only be calculated for numeric columns\n",
    "    if pd.api.types.is_numeric_dtype(data[column]):\n",
    "        # Calculate the median of the column, skipping NA values\n",
    "        median_value = data[column].median(skipna=True)\n",
    "        # Fill NA values in the column with the calculated median\n",
    "        data[column] = data[column].fillna(median_value)\n",
    "X = data.drop(columns='lineThresh')\n",
    "X = X.fillna(-1)\n",
    "y = data['lineThresh']\n",
    "X, encoder, scaler = autoencode_features(X)\n",
    "\n",
    "param_grid = {\n",
    "    'n_steps': [200, 500, 100],  # Example values\n",
    "    'lr': [0.01, 0.001, .1],  # Learning rates\n",
    "    'batch_size': [250, 500, 1000]  # Batch sizes\n",
    "}\n",
    "\n",
    "# Initialize a list to store the results of each configuration\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e333e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(data):\n",
    "    \"\"\"\n",
    "    Prepares labels for the Over and Under models.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame containing the original labels under 'lineThresh'\n",
    "\n",
    "    Returns:\n",
    "    - y_over: Labels for the Over model\n",
    "    - y_under: Labels for the Under model, which are simply the inverted labels of y_over\n",
    "    \"\"\"\n",
    "    y_over = data['lineThresh'].copy()\n",
    "    # Assuming binary classification where '1' is over and '0' is under,\n",
    "    # for the under model, we invert the labels\n",
    "    y_under = 1 - y_over\n",
    "    return y_over, y_under\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Assume PyroBayesianLogisticRegression and your cross-validation scheme are defined\n",
    "\n",
    "def train_model(X, y, param_grid):\n",
    "    \"\"\"\n",
    "    Trains the model using grid search and cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features for training the model.\n",
    "    - y: Labels for training the model.\n",
    "    - param_grid: Dictionary defining the grid of parameters to search.\n",
    "\n",
    "    Returns:\n",
    "    - best_score: The best precision score obtained.\n",
    "    - best_params: The parameters corresponding to the best score.\n",
    "    - best_model: The trained model with the best parameters.\n",
    "    \"\"\"\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        # Initialize the model with current parameters\n",
    "        blr = PyroBayesianLogisticRegression(n_steps=n_steps, lr=lr, batch_size=batch_size)\n",
    "        loocv = KFoldCrossValidationBobby(blr, n_jobs=10, n_splits=10)\n",
    "\n",
    "            # Perform the cross-validation. Assuming you have a method `cross_validate` that returns the evaluation metric(s)\n",
    "            # Note: This step is pseudo-code. You will need to implement or adjust the cross_validate method based on your setup.\n",
    "        avg_precision = loocv.cross_validate(X, y)  # X and y should be your data and labels respectively\n",
    "\n",
    "#         avg_precision = loocv.cross_validate(X, y)\n",
    "        \n",
    "        # Calculate average precision across folds\n",
    "#         avg_precision = sum(cv_scores) / len(cv_scores)\n",
    "        \n",
    "        if avg_precision > best_score:\n",
    "            best_score = avg_precision\n",
    "            best_params = params\n",
    "            # Retrain on the entire dataset with the best parameters (for simplicity, we re-use the variable 'model')\n",
    "            best_model = PyroBayesianLogisticRegression(n_steps=params['n_steps'], lr=params['lr'], batch_size=params['batch_size'])\n",
    "            best_model.fit(X, y)  # Assuming .fit() method exists and works as expected\n",
    "\n",
    "    return best_score, best_params, best_model\n",
    "\n",
    "def fill_na_with_median(data):\n",
    "    for column in data.columns:\n",
    "        if pd.api.types.is_numeric_dtype(data[column]):\n",
    "            median_value = data[column].median(skipna=True)\n",
    "            data[column] = data[column].fillna(median_value)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "86968a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6c876b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1714: early stopping\n",
      "Epoch 2300: early stopping\n",
      "Epoch 1959: early stopping\n",
      "Epoch 1708: early stopping\n",
      "Epoch 1998: early stopping\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# Assuming PyroBayesianLogisticRegression and other custom functions are defined elsewhere\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "for index, row in lines.iterrows():\n",
    "    try:\n",
    "        # Process row to prepare the data\n",
    "        data = process_row(row, server, database)\n",
    "        data = data.sort_values(by='GAME_DATE').reset_index(drop=True).iloc[1:]\n",
    "        data = data.drop(columns=['PLAYER_ID', 'GAME_DATE', 'LineType'])\n",
    "\n",
    "        # Fill NA values and prepare features and labels\n",
    "        data = fill_na_with_median(data)  # Assume implementation of this function based on your NA handling\n",
    "        y_over, y_under = prepare_labels(data)  # Assume you modify labels here for over and under\n",
    "\n",
    "        X = data.drop(columns='lineThresh')\n",
    "        X = X.fillna(-1)\n",
    "\n",
    "        # Autoencode features (assuming this function exists and returns encoded features, an encoder, and a scaler)\n",
    "        X_encoded, encoder, scaler = autoencode_features(X)\n",
    "\n",
    "        # Define parameter grid (same as your original grid)\n",
    "        param_grid = {\n",
    "            'n_steps': [200, 500, 100],\n",
    "            'lr': [0.01, 0.001, .1],\n",
    "            'batch_size': [250, 500, 1000]\n",
    "        }\n",
    "\n",
    "        # Train Over Model\n",
    "        over_model_results = train_model(X_encoded, y_over, param_grid)\n",
    "        # Train Under Model (with swapped labels)\n",
    "        under_model_results = train_model(X_encoded, y_under, param_grid)\n",
    "\n",
    "        # Select the best model based on precision score\n",
    "        # Assuming train_model returns (best_score, best_params, fitted_model)\n",
    "        if over_model_results[0] > under_model_results[0]:  # Compare precision scores\n",
    "            best_model = over_model_results[2]  # Use Over Model\n",
    "            label = 'Over'\n",
    "        else:\n",
    "            best_model = under_model_results[2]  # Use Under Model\n",
    "            label = 'Under'\n",
    "        # Predict using the selected model\n",
    "        pred = process_row_pred(row, server, database)\n",
    "        pred = pred.fillna(-1)\n",
    "        # data_scaled = scaler.transform(pred[features].drop(columns=['lineThresh']))\n",
    "        data_scaled = scaler.transform(pred[features].drop(columns=['lineThresh']))\n",
    "        pred = encoder.predict(data_scaled, verbose=False, use_multiprocessing=True)\n",
    "        pred_proba = best_model.predict_proba(pred)\n",
    "\n",
    "        # Prepare output DataFrame\n",
    "        temp = pd.DataFrame([[row['PLAYER_NAME'], row['Team'], row['line_Type'], row['Line'], label, pred_proba, max(over_model_results[0], under_model_results[0])]], columns=['Player', 'Team', 'line_Type', 'Line', 'Prediction', 'Proba', 'Model Score'])\n",
    "        output = pd.concat([output, temp])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(row['PLAYER_NAME'], row['Line'], str(e))\n",
    "\n",
    "# Helper functions like fill_na_with_median, prepare_labels, train_model, etc., are assumed to be defined elsewhere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df920d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>line_Type</th>\n",
       "      <th>Line</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Proba</th>\n",
       "      <th>Model Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dorian Finney-Smith</td>\n",
       "      <td>BKN</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>14.5</td>\n",
       "      <td>Under</td>\n",
       "      <td>0.40123212</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dorian Finney-Smith</td>\n",
       "      <td>BKN</td>\n",
       "      <td>PTS</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Over</td>\n",
       "      <td>0.71996397</td>\n",
       "      <td>0.643333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dennis Schroder</td>\n",
       "      <td>BKN</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>22.5</td>\n",
       "      <td>Under</td>\n",
       "      <td>0.54812765</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jalen Suggs</td>\n",
       "      <td>ORL</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>16.5</td>\n",
       "      <td>Over</td>\n",
       "      <td>0.9417015</td>\n",
       "      <td>0.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tre Jones</td>\n",
       "      <td>SAS</td>\n",
       "      <td>REB</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Under</td>\n",
       "      <td>0.0007588118</td>\n",
       "      <td>0.558571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Team    line_Type  Line Prediction         Proba  \\\n",
       "0  Dorian Finney-Smith  BKN  PTS+REB+AST  14.5      Under    0.40123212   \n",
       "0  Dorian Finney-Smith  BKN          PTS   7.5       Over    0.71996397   \n",
       "0      Dennis Schroder  BKN  PTS+REB+AST  22.5      Under    0.54812765   \n",
       "0          Jalen Suggs  ORL  PTS+REB+AST  16.5       Over     0.9417015   \n",
       "0            Tre Jones  SAS          REB   3.5      Under  0.0007588118   \n",
       "\n",
       "   Model Score  \n",
       "0     0.480000  \n",
       "0     0.643333  \n",
       "0     0.416667  \n",
       "0     0.613333  \n",
       "0     0.558571  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output.sort_values(by='Proba', ascending=False)\n",
    "send_email(f'Daily Line Picks for {str(date.today())}(Picky Bayes(With Embedding))', 'bobby.plourde12@yahoo.com', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfe7f189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2228: early stopping\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame()\n",
    "for index,row in lines.iterrows():\n",
    "    try:\n",
    "        data = process_row(row,server,database)\n",
    "        data = data.sort_values(by='GAME_DATE').reset_index(drop=True).iloc[1:]\n",
    "\n",
    "        data = data.drop(columns=['PLAYER_ID','GAME_DATE','LineType'])\n",
    "        features = data.columns\n",
    "        for column in data.columns:\n",
    "            # Check if the column is numeric, as median can only be calculated for numeric columns\n",
    "            if pd.api.types.is_numeric_dtype(data[column]):\n",
    "                # Calculate the median of the column, skipping NA values\n",
    "                median_value = data[column].median(skipna=True)\n",
    "                # Fill NA values in the column with the calculated median\n",
    "                data[column] = data[column].fillna(median_value)\n",
    "        X = data.drop(columns='lineThresh')\n",
    "        X = X.fillna(-1)\n",
    "        y = data['lineThresh']\n",
    "        X, encoder, scaler = autoencode_features(X)\n",
    "\n",
    "        param_grid = {\n",
    "            'n_steps': [200, 500, 100],  # Example values\n",
    "            'lr': [0.01, 0.001, .1],  # Learning rates\n",
    "            'batch_size': [250, 500, 1000]  # Batch sizes\n",
    "        }\n",
    "\n",
    "        # Initialize a list to store the results of each configuration\n",
    "        results = []\n",
    "\n",
    "        # Iterate over every combination in the parameter grid\n",
    "        for params in ParameterGrid(param_grid):\n",
    "            # Unpack parameters\n",
    "            n_steps = params['n_steps']\n",
    "            lr = params['lr']\n",
    "            batch_size = params['batch_size']\n",
    "\n",
    "            # Initialize your model and cross-validation scheme with the current set of parameters\n",
    "            blr = PyroBayesianLogisticRegression(n_steps=n_steps, lr=lr, batch_size=batch_size)\n",
    "            loocv = KFoldCrossValidationBobby(blr, n_jobs=10, n_splits=10)\n",
    "\n",
    "            # Perform the cross-validation. Assuming you have a method `cross_validate` that returns the evaluation metric(s)\n",
    "            # Note: This step is pseudo-code. You will need to implement or adjust the cross_validate method based on your setup.\n",
    "            score = loocv.cross_validate(X, y)  # X and y should be your data and labels respectively\n",
    "\n",
    "            # Store the results\n",
    "            results.append((score, params))\n",
    "\n",
    "        # Find the best parameter set based on the evaluation metric. Assuming higher score is better.\n",
    "        best_score, best_params = max(results, key=lambda x: x[0])\n",
    "\n",
    "        batch_size = best_params['batch_size']\n",
    "        lr = best_params['lr']\n",
    "        n_steps = best_params['n_steps']\n",
    "\n",
    "        blr = PyroBayesianLogisticRegression(n_steps=n_steps, lr=lr, batch_size=batch_size)\n",
    "        blr.fit(X,y)\n",
    "\n",
    "        pred = process_row_pred(row,server,database)\n",
    "        data_scaled = scaler.transform(pred[features].drop(columns=['lineThresh']))\n",
    "        pred = encoder.predict(data_scaled, verbose=False, use_multiprocessing=True)\n",
    "        pred_proba = blr.predict_proba(pred)\n",
    "\n",
    "        temp = pd.DataFrame([[row['PLAYER_NAME'],row['Team'],row['line_Type'],row['Line'],pred_proba,best_score]],columns=['Player','Team','line_Type','Line','Proba','Model Score']) \n",
    "\n",
    "        output = pd.concat([output,temp])\n",
    "    except:\n",
    "        print(row['PLAYER_NAME'],row['Line'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86852f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.sort_values(by='Proba', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743693f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705eb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "send_email(f'Daily Line Picks for {str(date.today())}(Picky Bayes(With Embedding))', 'bobby.plourde12@yahoo.com', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2466352a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a2dae848",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array 1 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26600\\3728315056.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# Calculate the F1 score for the current threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# Update the best score and best threshold if the current score is better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\T-drive\\Jupyter\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \"\"\"\n\u001b[1;32m-> 1123\u001b[1;33m     return fbeta_score(\n\u001b[0m\u001b[0;32m   1124\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\T-drive\\Jupyter\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \"\"\"\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1262\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\T-drive\\Jupyter\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\T-drive\\Jupyter\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average has to be one of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\T-drive\\Jupyter\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\T-drive\\Jupyter\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \"\"\"\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\T-drive\\Jupyter\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \"\"\"\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\T-drive\\Jupyter\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    270\u001b[0m                 \u001b[1;34m\"Singleton array %r cannot be considered a valid collection.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             )\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array 1 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "for threshold in thresholds:\n",
    "        # Convert predicted probabilities to binary predictions based on the current threshold\n",
    "        pred_labels = (pred_proba >= threshold).astype(int)\n",
    "\n",
    "        # Calculate the F1 score for the current threshold\n",
    "        score = f1_score(y, pred_labels)\n",
    "\n",
    "        # Update the best score and best threshold if the current score is better\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0fc01dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predicts: 0.55525535 model score is: 0.6463492063492065\n"
     ]
    }
   ],
   "source": [
    "print('model predicts:',pred_proba,'model score is:',best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a0f3bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_row(row,server,database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5860c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by='GAME_DATE').reset_index(drop=True).iloc[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "67702907",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['PLAYER_ID','GAME_DATE','LineType'])\n",
    "features = data.columns\n",
    "for column in data.columns:\n",
    "    # Check if the column is numeric, as median can only be calculated for numeric columns\n",
    "    if pd.api.types.is_numeric_dtype(data[column]):\n",
    "        # Calculate the median of the column, skipping NA values\n",
    "        median_value = data[column].median(skipna=True)\n",
    "        # Fill NA values in the column with the calculated median\n",
    "        data[column] = data[column].fillna(median_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c1e322a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns='lineThresh')\n",
    "y = data['lineThresh']\n",
    "X, encoder, scaler = autoencode_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ac65861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "lr = 0.001 \n",
    "n_steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d2300c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "blr = PyroBayesianLogisticRegression(n_steps=n_steps, lr=lr, batch_size=batch_size)\n",
    "loocv = KFoldCrossValidationBobby(blr, n_jobs=-1, n_splits=15)\n",
    "score = loocv.cross_validate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "215d9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "blr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "50daca68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6485714285714288"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f5aee4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.52450347, dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = process_row_pred(row,server,database)\n",
    "data_scaled = scaler.transform(pred[features].drop(columns=['lineThresh']))\n",
    "pred = encoder.predict(data_scaled, verbose=False, use_multiprocessing=True)\n",
    "pred_proba = blr.predict_proba(pred)\n",
    "pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "93aaf6a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5463492063492065\n",
      "0.3714285714285715\n",
      "0.5574603174603175\n",
      "0.5492063492063493\n",
      "0.6485714285714288\n",
      "0.4720634920634922\n",
      "0.41365079365079366\n",
      "0.4552380952380952\n",
      "0.4425396825396825\n",
      "0.5647619047619048\n",
      "0.4285714285714286\n",
      "0.42380952380952375\n",
      "0.6485714285714288\n",
      "0.6485714285714288\n",
      "0.5285714285714287\n",
      "0.4676190476190476\n",
      "0.3707936507936508\n",
      "0.32317460317460317\n",
      "0.48698412698412696\n",
      "0.43809523809523815\n",
      "0.4536507936507937\n",
      "0.6485714285714288\n",
      "0.6485714285714288\n",
      "0.4714285714285714\n",
      "0.3536507936507937\n",
      "0.40476190476190477\n",
      "0.4904761904761905\n",
      "Best Score: 0.6485714285714288\n",
      "Best Parameters: {'batch_size': 250, 'lr': 0.001, 'n_steps': 500}\n"
     ]
    }
   ],
   "source": [
    "# Define your parameter grid as a dictionary. Adjust the values according to your needs.\n",
    "param_grid = {\n",
    "    'n_steps': [200, 500, 100],  # Example values\n",
    "    'lr': [0.01, 0.001, .1],  # Learning rates\n",
    "    'batch_size': [250, 500, 1000]  # Batch sizes\n",
    "}\n",
    "\n",
    "# Initialize a list to store the results of each configuration\n",
    "results = []\n",
    "\n",
    "# Iterate over every combination in the parameter grid\n",
    "for params in ParameterGrid(param_grid):\n",
    "    # Unpack parameters\n",
    "    n_steps = params['n_steps']\n",
    "    lr = params['lr']\n",
    "    batch_size = params['batch_size']\n",
    "    \n",
    "    # Initialize your model and cross-validation scheme with the current set of parameters\n",
    "    blr = PyroBayesianLogisticRegression(n_steps=n_steps, lr=lr, batch_size=batch_size)\n",
    "    loocv = KFoldCrossValidationBobby(blr, n_jobs=-1, n_splits=15)\n",
    "    \n",
    "    # Perform the cross-validation. Assuming you have a method `cross_validate` that returns the evaluation metric(s)\n",
    "    # Note: This step is pseudo-code. You will need to implement or adjust the cross_validate method based on your setup.\n",
    "    score = loocv.cross_validate(X, y)  # X and y should be your data and labels respectively\n",
    "    \n",
    "    # Store the results\n",
    "    print(score)\n",
    "    results.append((score, params))\n",
    "\n",
    "# Find the best parameter set based on the evaluation metric. Assuming higher score is better.\n",
    "best_score, best_params = max(results, key=lambda x: x[0])\n",
    "\n",
    "print(f\"Best Score: {best_score}\")\n",
    "print(f\"Best Parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e19ed25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6485714285714288, {'batch_size': 250, 'lr': 0.001, 'n_steps': 500}),\n",
       " (0.6485714285714288, {'batch_size': 500, 'lr': 0.001, 'n_steps': 200}),\n",
       " (0.6485714285714288, {'batch_size': 500, 'lr': 0.001, 'n_steps': 500}),\n",
       " (0.6485714285714288, {'batch_size': 1000, 'lr': 0.001, 'n_steps': 200}),\n",
       " (0.6485714285714288, {'batch_size': 1000, 'lr': 0.001, 'n_steps': 500}),\n",
       " (0.5647619047619048, {'batch_size': 500, 'lr': 0.01, 'n_steps': 200}),\n",
       " (0.5574603174603175, {'batch_size': 250, 'lr': 0.01, 'n_steps': 100}),\n",
       " (0.5492063492063493, {'batch_size': 250, 'lr': 0.001, 'n_steps': 200}),\n",
       " (0.5463492063492065, {'batch_size': 250, 'lr': 0.01, 'n_steps': 200}),\n",
       " (0.5285714285714287, {'batch_size': 500, 'lr': 0.001, 'n_steps': 100}),\n",
       " (0.4904761904761905, {'batch_size': 1000, 'lr': 0.1, 'n_steps': 100}),\n",
       " (0.48698412698412696, {'batch_size': 1000, 'lr': 0.01, 'n_steps': 200}),\n",
       " (0.4720634920634922, {'batch_size': 250, 'lr': 0.001, 'n_steps': 100}),\n",
       " (0.4714285714285714, {'batch_size': 1000, 'lr': 0.001, 'n_steps': 100}),\n",
       " (0.4676190476190476, {'batch_size': 500, 'lr': 0.1, 'n_steps': 200}),\n",
       " (0.4552380952380952, {'batch_size': 250, 'lr': 0.1, 'n_steps': 500}),\n",
       " (0.4536507936507937, {'batch_size': 1000, 'lr': 0.01, 'n_steps': 100}),\n",
       " (0.4425396825396825, {'batch_size': 250, 'lr': 0.1, 'n_steps': 100}),\n",
       " (0.43809523809523815, {'batch_size': 1000, 'lr': 0.01, 'n_steps': 500}),\n",
       " (0.4285714285714286, {'batch_size': 500, 'lr': 0.01, 'n_steps': 500}),\n",
       " (0.42380952380952375, {'batch_size': 500, 'lr': 0.01, 'n_steps': 100}),\n",
       " (0.41365079365079366, {'batch_size': 250, 'lr': 0.1, 'n_steps': 200}),\n",
       " (0.40476190476190477, {'batch_size': 1000, 'lr': 0.1, 'n_steps': 500}),\n",
       " (0.3714285714285715, {'batch_size': 250, 'lr': 0.01, 'n_steps': 500}),\n",
       " (0.3707936507936508, {'batch_size': 500, 'lr': 0.1, 'n_steps': 500}),\n",
       " (0.3536507936507937, {'batch_size': 1000, 'lr': 0.1, 'n_steps': 200}),\n",
       " (0.32317460317460317, {'batch_size': 500, 'lr': 0.1, 'n_steps': 100})]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c34a8a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6060441880101323, {'batch_size': 250, 'lr': 0.01, 'n_steps': 200}),\n",
       " (0.596236969234681, {'batch_size': 1000, 'lr': 0.01, 'n_steps': 200}),\n",
       " (0.5772311212814646, {'batch_size': 250, 'lr': 0.01, 'n_steps': 100}),\n",
       " (0.5643775213434656, {'batch_size': 500, 'lr': 0.01, 'n_steps': 200}),\n",
       " (0.5380434782608696, {'batch_size': 500, 'lr': 0.01, 'n_steps': 500}),\n",
       " (0.5332590115198811, {'batch_size': 500, 'lr': 0.1, 'n_steps': 200}),\n",
       " (0.5289855072463768, {'batch_size': 500, 'lr': 0.1, 'n_steps': 500}),\n",
       " (0.5113087395696092, {'batch_size': 250, 'lr': 0.1, 'n_steps': 100}),\n",
       " (0.5050088990592423, {'batch_size': 500, 'lr': 0.01, 'n_steps': 100}),\n",
       " (0.5050088990592423, {'batch_size': 500, 'lr': 0.001, 'n_steps': 200}),\n",
       " (0.4956521739130435, {'batch_size': 1000, 'lr': 0.1, 'n_steps': 100}),\n",
       " (0.43834223239257564, {'batch_size': 250, 'lr': 0.001, 'n_steps': 100}),\n",
       " (0.43834223239257564, {'batch_size': 500, 'lr': 0.001, 'n_steps': 100}),\n",
       " (0.43834223239257564, {'batch_size': 1000, 'lr': 0.001, 'n_steps': 200}),\n",
       " (0.4382992327365729, {'batch_size': 1000, 'lr': 0.1, 'n_steps': 200}),\n",
       " (0.42450824029771406, {'batch_size': 500, 'lr': 0.001, 'n_steps': 500}),\n",
       " (0.4093567251461988, {'batch_size': 250, 'lr': 0.001, 'n_steps': 500}),\n",
       " (0.3956521739130435, {'batch_size': 250, 'lr': 0.01, 'n_steps': 500}),\n",
       " (0.3538011695906432, {'batch_size': 250, 'lr': 0.001, 'n_steps': 200}),\n",
       " (0.3277777777777778, {'batch_size': 1000, 'lr': 0.01, 'n_steps': 500}),\n",
       " (0.3146997929606625, {'batch_size': 1000, 'lr': 0.1, 'n_steps': 500}),\n",
       " (0.3132992327365729, {'batch_size': 250, 'lr': 0.1, 'n_steps': 200}),\n",
       " (0.30935672514619883, {'batch_size': 1000, 'lr': 0.001, 'n_steps': 500}),\n",
       " (0.24269005847953218, {'batch_size': 1000, 'lr': 0.001, 'n_steps': 100}),\n",
       " (0.2048611111111111, {'batch_size': 1000, 'lr': 0.01, 'n_steps': 100}),\n",
       " (0.20238095238095238, {'batch_size': 250, 'lr': 0.1, 'n_steps': 500}),\n",
       " (0.16666666666666666, {'batch_size': 500, 'lr': 0.1, 'n_steps': 100})]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14fc101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "# Define your parameter grid\n",
    "param_grid = {\n",
    "    'n_steps': [200, 500, 100],  # Example values\n",
    "    'lr': [0.01, 0.001, 0.0001],  # Learning rates\n",
    "    'batch_size': [len(X), 100, 250]  # Batch sizes\n",
    "}\n",
    "\n",
    "# Define a function to train and evaluate a single model configuration\n",
    "def evaluate_model(params, X, y):\n",
    "    n_steps = params['n_steps']\n",
    "    lr = params['lr']\n",
    "    batch_size = params['batch_size']\n",
    "    \n",
    "    # Initialize your model with the current set of parameters\n",
    "    blr = PyroBayesianLogisticRegression(n_steps=n_steps, lr=lr, batch_size=batch_size)\n",
    "    loocv = KFoldCrossValidationBobby(blr, n_jobs=2, n_splits=4)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    # Note: This is pseudo-code. You will need to implement or adjust the cross_validate method.\n",
    "    score = loocv.cross_validate(X, y)  # X and y should be your data and labels respectively\n",
    "    \n",
    "    return score, params\n",
    "\n",
    "# Use joblib to parallelize the grid search\n",
    "# n_jobs=-1 uses all available CPU cores. Adjust based on your system's capability or desired usage.\n",
    "results = Parallel(n_jobs=-1,verbose=10)(\n",
    "    delayed(evaluate_model)(params, X, y) for params in ParameterGrid(param_grid)\n",
    ")\n",
    "\n",
    "# Find the best parameter set based on the evaluation metric\n",
    "best_score, best_params = max(results, key=lambda x: x[0])\n",
    "\n",
    "print(f\"Best Score: {best_score}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf1a0463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>lineThresh</th>\n",
       "      <th>daysOfRest</th>\n",
       "      <th>secondHalfOfBackToBack</th>\n",
       "      <th>PlayerGotLastMeeting</th>\n",
       "      <th>NumberTimesHitAgaisntOppLast2</th>\n",
       "      <th>NumberTimesHitAgaisntOppLast5</th>\n",
       "      <th>PerGameAgainstOppLast2</th>\n",
       "      <th>PerGameAgainstOppLast5</th>\n",
       "      <th>...</th>\n",
       "      <th>DefRatingShortVsMedium</th>\n",
       "      <th>MPGRecentVsOffRating</th>\n",
       "      <th>FantPtsVsTeamNetRating</th>\n",
       "      <th>OffRatingVsNetRatingLong</th>\n",
       "      <th>OffRatingMediumVsDefRating</th>\n",
       "      <th>DefRatingVsTeamORating</th>\n",
       "      <th>FantPtsLongVsAvgPtsAllowedRecent</th>\n",
       "      <th>FantPtsVsDefRating</th>\n",
       "      <th>OffRatingVsPTSOffTOTrend</th>\n",
       "      <th>LineType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1627827</td>\n",
       "      <td>2024-03-16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13.33</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12623.9631</td>\n",
       "      <td>2859.9377</td>\n",
       "      <td>29.498</td>\n",
       "      <td>-35.8645</td>\n",
       "      <td>13246.6698</td>\n",
       "      <td>13224.7191</td>\n",
       "      <td>2183.27</td>\n",
       "      <td>2434.2171</td>\n",
       "      <td>102.47</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PLAYER_ID   GAME_DATE  lineThresh  daysOfRest  secondHalfOfBackToBack  \\\n",
       "0    1627827  2024-03-16           1           2                       0   \n",
       "\n",
       "   PlayerGotLastMeeting  NumberTimesHitAgaisntOppLast2  \\\n",
       "0                    13                              1   \n",
       "\n",
       "   NumberTimesHitAgaisntOppLast5  PerGameAgainstOppLast2  \\\n",
       "0                              3                   13.33   \n",
       "\n",
       "   PerGameAgainstOppLast5  ...  DefRatingShortVsMedium  MPGRecentVsOffRating  \\\n",
       "0                    16.0  ...              12623.9631             2859.9377   \n",
       "\n",
       "   FantPtsVsTeamNetRating  OffRatingVsNetRatingLong  \\\n",
       "0                  29.498                  -35.8645   \n",
       "\n",
       "   OffRatingMediumVsDefRating  DefRatingVsTeamORating  \\\n",
       "0                  13246.6698              13224.7191   \n",
       "\n",
       "   FantPtsLongVsAvgPtsAllowedRecent  FantPtsVsDefRating  \\\n",
       "0                           2183.27           2434.2171   \n",
       "\n",
       "   OffRatingVsPTSOffTOTrend     LineType  \n",
       "0                    102.47  PTS+REB+AST  \n",
       "\n",
       "[1 rows x 332 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_row_pred(lines.iloc[0],server,database)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
