{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88ab72bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bobby\\OneDrive\\T-drive\\Jupyter\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "from slugify import slugify\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "# import numpy as np \n",
    "import pyodbc\n",
    "from slugify import slugify\n",
    "from datetime import date\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from pycaret.classification import setup, compare_models, tune_model, save_model, blend_models, create_model, calibrate_model, predict_model\n",
    "\n",
    "from sklearn.metrics import f1_score,accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "import logging\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils import send_email\n",
    "\n",
    "np.random.seed(4407)  # Setting the numpy seed for global usage in this script\n",
    "tf.random.set_seed(4407)  # for TensorFlow operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe05b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\bobby\\Downloads\\all_rotowire_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8265087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the names of columns to drop\n",
    "columns_to_drop = []\n",
    "\n",
    "# Initialize a set to keep track of seen (cleaned) column names\n",
    "seen_columns = set()\n",
    "\n",
    "# Iterate over the columns\n",
    "for col in df.columns:\n",
    "    # Remove trailing numbers and dots from column names to find the \"base\" name\n",
    "    cleaned_col = col.rstrip('1234567890. ')\n",
    "    \n",
    "    # If the cleaned column name is already seen, mark the original column for removal\n",
    "    if cleaned_col in seen_columns:\n",
    "        columns_to_drop.append(col)\n",
    "    else:\n",
    "        # Otherwise, add the cleaned name to the set of seen column names\n",
    "        seen_columns.add(cleaned_col)\n",
    "\n",
    "# Drop the marked columns from the DataFrame\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a226540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'localhost\\SQLEXPRESS'\n",
    "database = 'nba_game_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b936192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Position</th>\n",
       "      <th>Team</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Market Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Site Less</th>\n",
       "      <th>Site More</th>\n",
       "      <th>...</th>\n",
       "      <th>FanDuel Line</th>\n",
       "      <th>FanDuel Less</th>\n",
       "      <th>FanDuel More</th>\n",
       "      <th>FanDuel Less %</th>\n",
       "      <th>FanDuel More %</th>\n",
       "      <th>PointsBet Line</th>\n",
       "      <th>PointsBet Less</th>\n",
       "      <th>PointsBet More</th>\n",
       "      <th>PointsBet Less %</th>\n",
       "      <th>PointsBet More %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kentavious Caldwell-Pope</td>\n",
       "      <td>G</td>\n",
       "      <td>DEN</td>\n",
       "      <td>@SAS</td>\n",
       "      <td>3/15/2024</td>\n",
       "      <td>7:30 PM</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-122</td>\n",
       "      <td>-137</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-130</td>\n",
       "      <td>100</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tre Jones</td>\n",
       "      <td>G</td>\n",
       "      <td>SAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>3/15/2024</td>\n",
       "      <td>7:30 PM</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>17.5</td>\n",
       "      <td>-121</td>\n",
       "      <td>-139</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5</td>\n",
       "      <td>100</td>\n",
       "      <td>-128</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>17.5</td>\n",
       "      <td>-110</td>\n",
       "      <td>-120</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kentavious Caldwell-Pope</td>\n",
       "      <td>G</td>\n",
       "      <td>DEN</td>\n",
       "      <td>@SAS</td>\n",
       "      <td>3/15/2024</td>\n",
       "      <td>7:30 PM</td>\n",
       "      <td>Points</td>\n",
       "      <td>8.5</td>\n",
       "      <td>-136</td>\n",
       "      <td>-124</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-132</td>\n",
       "      <td>104</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>8.5</td>\n",
       "      <td>-110</td>\n",
       "      <td>-120</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dejounte Murray</td>\n",
       "      <td>G</td>\n",
       "      <td>ATL</td>\n",
       "      <td>@UTA</td>\n",
       "      <td>3/15/2024</td>\n",
       "      <td>8:30 PM</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>41.5</td>\n",
       "      <td>-139</td>\n",
       "      <td>-121</td>\n",
       "      <td>...</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-111</td>\n",
       "      <td>-115</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-110</td>\n",
       "      <td>-120</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Herbert Jones</td>\n",
       "      <td>F</td>\n",
       "      <td>NOP</td>\n",
       "      <td>LAC</td>\n",
       "      <td>3/15/2024</td>\n",
       "      <td>7:00 PM</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-117</td>\n",
       "      <td>-143</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.5</td>\n",
       "      <td>-130</td>\n",
       "      <td>100</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>Nick Richards</td>\n",
       "      <td>C</td>\n",
       "      <td>CHA</td>\n",
       "      <td>@PHI</td>\n",
       "      <td>3/16/2024</td>\n",
       "      <td>6:00 PM</td>\n",
       "      <td>Assists</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-137</td>\n",
       "      <td>-122</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-125</td>\n",
       "      <td>-105</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>Jaren Jackson</td>\n",
       "      <td>C</td>\n",
       "      <td>MEM</td>\n",
       "      <td>OKC</td>\n",
       "      <td>3/16/2024</td>\n",
       "      <td>7:00 PM</td>\n",
       "      <td>PTS+REB+AST</td>\n",
       "      <td>32.5</td>\n",
       "      <td>-125</td>\n",
       "      <td>-136</td>\n",
       "      <td>...</td>\n",
       "      <td>32.5</td>\n",
       "      <td>-108</td>\n",
       "      <td>-118</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>32.5</td>\n",
       "      <td>-110</td>\n",
       "      <td>-120</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>Dillon Brooks</td>\n",
       "      <td>F</td>\n",
       "      <td>HOU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>3/16/2024</td>\n",
       "      <td>4:00 PM</td>\n",
       "      <td>Rebounds</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-130</td>\n",
       "      <td>-129</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-118</td>\n",
       "      <td>-108</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-115</td>\n",
       "      <td>-115</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>Fred VanVleet</td>\n",
       "      <td>G</td>\n",
       "      <td>HOU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>3/16/2024</td>\n",
       "      <td>4:00 PM</td>\n",
       "      <td>Steals</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-152</td>\n",
       "      <td>-112</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-122</td>\n",
       "      <td>-104</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>Anthony Edwards</td>\n",
       "      <td>G</td>\n",
       "      <td>MIN</td>\n",
       "      <td>@UTA</td>\n",
       "      <td>3/16/2024</td>\n",
       "      <td>8:30 PM</td>\n",
       "      <td>3PT Made</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-143</td>\n",
       "      <td>-118</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-115</td>\n",
       "      <td>-111</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-120</td>\n",
       "      <td>-110</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>968 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Player Position Team Opponent       Date     Time  \\\n",
       "0    Kentavious Caldwell-Pope        G  DEN     @SAS  3/15/2024  7:30 PM   \n",
       "1                   Tre Jones        G  SAS      DEN  3/15/2024  7:30 PM   \n",
       "2    Kentavious Caldwell-Pope        G  DEN     @SAS  3/15/2024  7:30 PM   \n",
       "3             Dejounte Murray        G  ATL     @UTA  3/15/2024  8:30 PM   \n",
       "4               Herbert Jones        F  NOP      LAC  3/15/2024  7:00 PM   \n",
       "..                        ...      ...  ...      ...        ...      ...   \n",
       "963             Nick Richards        C  CHA     @PHI  3/16/2024  6:00 PM   \n",
       "964             Jaren Jackson        C  MEM      OKC  3/16/2024  7:00 PM   \n",
       "965             Dillon Brooks        F  HOU      CLE  3/16/2024  4:00 PM   \n",
       "966             Fred VanVleet        G  HOU      CLE  3/16/2024  4:00 PM   \n",
       "967           Anthony Edwards        G  MIN     @UTA  3/16/2024  8:30 PM   \n",
       "\n",
       "     Market Name  Line  Site Less  Site More  ...  FanDuel Line FanDuel Less  \\\n",
       "0    PTS+REB+AST  12.5       -122       -137  ...             -            -   \n",
       "1    PTS+REB+AST  17.5       -121       -139  ...          17.5          100   \n",
       "2         Points   8.5       -136       -124  ...           9.5         -132   \n",
       "3    PTS+REB+AST  41.5       -139       -121  ...          40.5         -111   \n",
       "4    PTS+REB+AST  14.5       -117       -143  ...             -            -   \n",
       "..           ...   ...        ...        ...  ...           ...          ...   \n",
       "963      Assists   0.5       -137       -122  ...             -            -   \n",
       "964  PTS+REB+AST  32.5       -125       -136  ...          32.5         -108   \n",
       "965     Rebounds   3.5       -130       -129  ...           3.5         -118   \n",
       "966       Steals   1.5       -152       -112  ...           1.5         -122   \n",
       "967     3PT Made   2.5       -143       -118  ...           2.5         -115   \n",
       "\n",
       "    FanDuel More FanDuel Less %  FanDuel More %  PointsBet Line  \\\n",
       "0              -              -               -            13.5   \n",
       "1           -128             47              53            17.5   \n",
       "2            104             54              46             8.5   \n",
       "3           -115             50              50            40.5   \n",
       "4              -              -               -            15.5   \n",
       "..           ...            ...             ...             ...   \n",
       "963            -              -               -             0.5   \n",
       "964         -118             49              51            32.5   \n",
       "965         -108             51              49             3.5   \n",
       "966         -104             52              48               -   \n",
       "967         -111             50              50             2.5   \n",
       "\n",
       "     PointsBet Less  PointsBet More PointsBet Less % PointsBet More %  \n",
       "0              -130             100               53               47  \n",
       "1              -110            -120               49               51  \n",
       "2              -110            -120               49               51  \n",
       "3              -110            -120               49               51  \n",
       "4              -130             100               53               47  \n",
       "..              ...             ...              ...              ...  \n",
       "963            -125            -105               52               48  \n",
       "964            -110            -120               49               51  \n",
       "965            -115            -115               50               50  \n",
       "966               -               -                -                -  \n",
       "967            -120            -110               51               49  \n",
       "\n",
       "[968 rows x 66 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a46f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['line_Type'] = ''\n",
    "for i, row in df.iterrows():\n",
    "    if row['Market Name'] == 'Rebounds':\n",
    "        df.loc[i,'line_Type'] ='REB'\n",
    "    elif row['Market Name'] == '3PT Made':\n",
    "        df.loc[i,'line_Type'] ='FG3M'\n",
    "    elif row['Market Name'] == 'Assists':\n",
    "        df.loc[i,'line_Type'] ='AST'\n",
    "    elif row['Market Name'] == 'Blocks':\n",
    "        df.loc[i,'line_Type'] ='BLK'\n",
    "    elif row['Market Name'] == 'PTS+REB+AST':\n",
    "        df.loc[i,'line_Type'] ='PTS+REB+AST'\n",
    "    elif row['Market Name'] == 'Turnovers':\n",
    "        df.loc[i,'line_Type'] ='TOV'\n",
    "    elif row['Market Name'] == 'Points':\n",
    "        df.loc[i,'line_Type'] ='PTS'\n",
    "    elif row['Market Name'] == 'Steals':\n",
    "        df.loc[i,'line_Type'] ='STL'\n",
    "        \n",
    "df['Opponent'] = df['Opponent'].apply(lambda x: x.replace('@','').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4ec9453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "# Slugify player names for both DataFrames\n",
    "df['Player_Slug'] = df['Player'].apply(slugify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "996d1dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bobby\\AppData\\Local\\Temp\\ipykernel_15888\\955121673.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_actuals = pd.read_sql(sql,cnxn)\n"
     ]
    }
   ],
   "source": [
    "import pyodbc \n",
    "server = 'localhost\\SQLEXPRESS'\n",
    "database = 'nba_game_data'\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';')\n",
    "cursor = cnxn.cursor()\n",
    "sql = \"\"\"\n",
    "SELECT \n",
    "      [PLAYER_NAME]\n",
    "      ,PLAYER_ID\n",
    "      ,[GAME_DATE]\n",
    "      ,[REB]\n",
    "      ,[AST]\n",
    "      ,[TOV]\n",
    "      ,[STL]\n",
    "      ,[BLK]\n",
    "      ,[PTS]\n",
    "      ,FG3M\n",
    "\n",
    "  FROM [nba_game_data].[dbo].[PlayerGameLogs]\n",
    "  where yearSeason=2024\n",
    "  \"\"\"\n",
    "df_actuals = pd.read_sql(sql,cnxn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0b6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Player_Slug'] = df['Player'].apply(slugify)\n",
    "df_actuals['GAME_DATE'] = pd.to_datetime(df_actuals['GAME_DATE'])\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df_actuals['Player_Slug'] = df_actuals['PLAYER_NAME'].apply(slugify)\n",
    "df_combined = pd.merge(df, df_actuals, how='left', left_on = ['Player_Slug','Date'],right_on=['Player_Slug','GAME_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cce7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['actual'] = None\n",
    "for i, row in df_combined.iterrows():\n",
    "    if row['Market Name'] == 'Rebounds':\n",
    "        df_combined.loc[i,'actual'] = df_combined.loc[i,'REB']\n",
    "    elif row['Market Name'] == '3PT Made':\n",
    "        df_combined.loc[i,'actual'] =df_combined.loc[i,'FG3M']\n",
    "    elif row['Market Name'] == 'Assists':\n",
    "        df_combined.loc[i,'actual'] =df_combined.loc[i,'AST']\n",
    "    elif row['Market Name'] == 'Blocks':\n",
    "        df_combined.loc[i,'actual'] =df_combined.loc[i,'BLK']\n",
    "    elif row['Market Name'] == 'PTS+REB+AST':\n",
    "        df_combined.loc[i,'actual'] =df_combined.loc[i,'PTS']+df_combined.loc[i,'REB']+df_combined.loc[i,'AST']\n",
    "    elif row['Market Name'] == 'Turnovers':\n",
    "        df_combined.loc[i,'actual'] =df_combined.loc[i,'TOV']\n",
    "    elif row['Market Name'] == 'Points':\n",
    "        df_combined.loc[i,'actual'] =df_combined.loc[i,'PTS']\n",
    "    elif row['Market Name'] == 'Steals':\n",
    "        df_combined.loc[i,'actual'] =df_combined.loc[i,'STL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "743973a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['over'] = (df_combined['actual']>df_combined['Line']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca154f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.dropna(subset='actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b6aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean column names\n",
    "def clean_column_name(column_name):\n",
    "    # Remove anything that is not a word character, a space, or a digit\n",
    "    cleaned_name = re.sub(r\"[^\\w\\s]\", '', column_name)\n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned_name = re.sub(r\"\\s+\", ' ', cleaned_name)\n",
    "    return cleaned_name\n",
    "\n",
    "# Clean all column names\n",
    "df_combined.columns = [clean_column_name(col) for col in df_combined.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdb398fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['Lean'] = df_combined['Lean'].apply(lambda x: 1 if x =='More' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcd386cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['At Home'] = df_combined['At Home'].apply(lambda x: 1 if x =='Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68cca7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46e05641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns you've identified as having meaningfully missing values\n",
    "columns_with_missing_values = df_combined.columns#['Site Less', 'Site More', 'PrizePicks Line', 'Underdog Line', 'DraftKings Pick6 Line', 'BetMGM Line', 'BetRivers Line', 'DraftKings Line', 'FanDuel Line', 'PointsBet Line']\n",
    "\n",
    "# Fill missing values with -1 for the specified columns\n",
    "for column in columns_with_missing_values:\n",
    "    df_combined[column] = df_combined[column].fillna(-1).replace('-',-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "279410fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['Weighted Recent and Season Hit Rate'] = (\n",
    "    0.6 * df_combined['Hit Rate Last 20 Outcomes'].astype(float).apply(lambda x: str(x).count('1')) / 20 +\n",
    "    0.4 * df_combined['Hit Rate Previous Season'].astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dbd735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Hit Rate Last 10 Outcomes', 'Hit Rate Last 20 Outcomes', 'Hit Rate Last 30 Outcomes', 'Hit Rate Last 5 Outcomes']\n",
    "\n",
    "# Loop through each column and calculate the sum of '1's for each row\n",
    "for column in columns:\n",
    "    # Assuming each cell is stored as a string of binary digits\n",
    "    # If not, you might need to convert them to strings first\n",
    "    df_combined[column] = df_combined[column].apply(lambda x: str(x).count('1'))\n",
    "\n",
    "# Now, each of the specified columns has an accompanying column with the suffix ' Sum'\n",
    "# that contains the sum of '1's, representing the number of games won.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f00c0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined[['Market Name','Opponent','Line', 'Site Less', 'Site More', 'Prediction', 'Lean',\n",
    "       'DFS Pickem Sites Factor', 'Sportsbooks Factor',\n",
    "       'RotoWire Projection Factor', 'Hit Rate Factor', 'RotoWire Projection',\n",
    "       'Weighted Hit Rate', 'At Home',\n",
    "       'Average Line Variance', 'Implied Less ', 'Implied More ',\n",
    "       'Hit Rate Last 10', 'Hit Rate Last 10 Outcomes',\n",
    "       'Hit Rate Last 20 Outcomes', 'Hit Rate Last 30 Outcomes',\n",
    "       'Hit Rate Last 5 Outcomes', 'Hit Rate Previous Season',\n",
    "       'Hit Rate Season', 'Hit Rate Vs Opponent',\n",
    "       'RotoWire Projection Difference', 'RotoWire Projection Difference ',\n",
    "       'PrizePicks', 'PrizePicks Line', 'Underdog', 'Underdog Line',\n",
    "       'DraftKings Pick6', 'DraftKings Pick6 Line', 'BetMGM Line',\n",
    "       'BetMGM Less', 'BetMGM More',\n",
    "       'BetRivers Line', 'BetRivers Less', 'BetRivers More',\n",
    "       'DraftKings Line', 'DraftKings Less',\n",
    "       'BetMGM More ', 'BetRivers More ', 'DraftKings More ', 'FanDuel More ',\n",
    "       'DraftKings More',\n",
    "       'FanDuel Line', 'FanDuel Less', 'FanDuel More',\n",
    "       'PointsBet Line', 'PointsBet Less', 'PointsBet More','BetMGM Less ', 'BetRivers Less ', 'DraftKings Less ', 'FanDuel Less ',\n",
    "       'over']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ba1fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['Performance Variability Vs Season'] = abs(df_combined['Hit Rate Vs Opponent'].astype(int) - df_combined['Hit Rate Season'].astype(int))\n",
    "df_combined['Home Advantage Factor'] = df_combined['At Home'] * df_combined['Hit Rate Season']\n",
    "df_combined['Projection Difference Momentum'] = df_combined['RotoWire Projection Difference'] - df_combined['RotoWire Projection Difference ']\n",
    "df_combined['RotoWire Projection Difference']\n",
    "df_combined['Predictive Confidence'] = (df_combined['Prediction'].astype(float) + df_combined['Sportsbooks Factor'].astype(float) + df_combined['DFS Pickem Sites Factor'].astype(float)) / 3\n",
    "df_combined['Recent Performance Trend'] = df_combined['Hit Rate Last 5 Outcomes'].apply(lambda x: str(x).count('1')) / 5 - df_combined['Hit Rate Last 30 Outcomes'].apply(lambda x: str(x).count('1')) / 30\n",
    "df_combined['Site Lean Disagreement'] = (df_combined['Site More'] - df_combined['Site Less']).abs()\n",
    "df_combined['Implied Probability Discrepancy'] = (df_combined['Implied More '] - df_combined['Implied Less ']).abs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4534b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -1 with NaN for calculation purposes in the specified columns\n",
    "betting_columns_less = ['BetMGM Less ', 'BetRivers Less ', 'DraftKings Less ', 'FanDuel Less ']\n",
    "betting_columns_more = ['BetMGM More ', 'BetRivers More ', 'DraftKings More ', 'FanDuel More ']\n",
    "line_columns = ['BetMGM Line', 'BetRivers Line', 'DraftKings Line', 'FanDuel Line', 'PointsBet Line']\n",
    "\n",
    "# Apply replacement\n",
    "df_temp_less = df_combined[betting_columns_less].replace(-1, np.nan).astype(float)\n",
    "df_temp_more = df_combined[betting_columns_more].replace(-1, np.nan).astype(float)\n",
    "df_temp_lines = df_combined[line_columns].replace(-1, np.nan).astype(float)\n",
    "\n",
    "# Calculate the mean for \"less\" and \"more\" consensus, ignoring NaN values\n",
    "df_combined['Betting Consensus Less'] = df_temp_less.mean(axis=1)\n",
    "df_combined['Betting Consensus More'] = df_temp_more.mean(axis=1)\n",
    "\n",
    "# Calculate the variance in betting lines across sites, ignoring NaN values\n",
    "df_combined['Betting Line Variance'] = df_temp_lines.var(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1faf9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.fillna(-1)\n",
    "# Replace infinite values with -1\n",
    "df_combined = df_combined.replace([np.inf, -np.inf], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db6c5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.drop(columns=['Opponent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae4ad731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_just_market = df_combined.loc[df_combined['Market Name']=='Points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "495833bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Site Less</th>\n",
       "      <th>Site More</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Lean</th>\n",
       "      <th>DFS Pickem Sites Factor</th>\n",
       "      <th>Sportsbooks Factor</th>\n",
       "      <th>RotoWire Projection Factor</th>\n",
       "      <th>Hit Rate Factor</th>\n",
       "      <th>RotoWire Projection</th>\n",
       "      <th>...</th>\n",
       "      <th>Performance Variability Vs Season</th>\n",
       "      <th>Home Advantage Factor</th>\n",
       "      <th>Projection Difference Momentum</th>\n",
       "      <th>Predictive Confidence</th>\n",
       "      <th>Recent Performance Trend</th>\n",
       "      <th>Site Lean Disagreement</th>\n",
       "      <th>Implied Probability Discrepancy</th>\n",
       "      <th>Betting Consensus Less</th>\n",
       "      <th>Betting Consensus More</th>\n",
       "      <th>Betting Line Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5</td>\n",
       "      <td>-136</td>\n",
       "      <td>-124</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>62.5</td>\n",
       "      <td>10.51</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.60</td>\n",
       "      <td>9.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>48.666667</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.5</td>\n",
       "      <td>-137</td>\n",
       "      <td>-124</td>\n",
       "      <td>-20.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-69.3</td>\n",
       "      <td>-52.5</td>\n",
       "      <td>18.42</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>8.06</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.5</td>\n",
       "      <td>-141</td>\n",
       "      <td>-120</td>\n",
       "      <td>-16.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>20.68</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>11.78</td>\n",
       "      <td>-6.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22.5</td>\n",
       "      <td>-139</td>\n",
       "      <td>-122</td>\n",
       "      <td>-14.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-96.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.60</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-4.933333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>49.750000</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.5</td>\n",
       "      <td>-150</td>\n",
       "      <td>-113</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.7</td>\n",
       "      <td>-30.9</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.49</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-20.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>18.5</td>\n",
       "      <td>-141</td>\n",
       "      <td>-120</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>-36.8</td>\n",
       "      <td>67.5</td>\n",
       "      <td>17.39</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4.87</td>\n",
       "      <td>-2.966667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>13.5</td>\n",
       "      <td>-132</td>\n",
       "      <td>-127</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>29.5</td>\n",
       "      <td>-27.5</td>\n",
       "      <td>14.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>-5.67</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>48.666667</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>19.5</td>\n",
       "      <td>-121</td>\n",
       "      <td>-139</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>19.25</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>48.666667</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>22.5</td>\n",
       "      <td>-121</td>\n",
       "      <td>-139</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>22.55</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>19.5</td>\n",
       "      <td>-127</td>\n",
       "      <td>-132</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>51.4</td>\n",
       "      <td>-57.5</td>\n",
       "      <td>21.04</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>51</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Line  Site Less  Site More  Prediction  Lean DFS Pickem Sites Factor  \\\n",
       "2     8.5       -136       -124        22.0     1                       0   \n",
       "5    20.5       -137       -124       -20.5     0                       0   \n",
       "11   24.5       -141       -120       -16.3     0                       0   \n",
       "14   22.5       -139       -122       -14.6     0                       0   \n",
       "15   11.5       -150       -113       -14.5     0                   -16.7   \n",
       "..    ...        ...        ...         ...   ...                     ...   \n",
       "941  18.5       -141       -120         1.1     1                       0   \n",
       "943  13.5       -132       -127         1.1     1                       0   \n",
       "950  19.5       -121       -139        -0.7     0                       0   \n",
       "952  22.5       -121       -139         0.7     1                       0   \n",
       "960  19.5       -127       -132        -0.5     0                       0   \n",
       "\n",
       "    Sportsbooks Factor  RotoWire Projection Factor  Hit Rate Factor  \\\n",
       "2                  7.5                        66.9             62.5   \n",
       "5                 -6.5                       -69.3            -52.5   \n",
       "11                -2.5                      -100.0             -2.5   \n",
       "14                -0.2                       -96.8              0.0   \n",
       "15               -30.9                        -0.4             15.0   \n",
       "..                 ...                         ...              ...   \n",
       "941                -10                       -36.8             67.5   \n",
       "943                2.2                        29.5            -27.5   \n",
       "950                2.4                        -8.2             -2.5   \n",
       "952                7.7                         1.8            -15.0   \n",
       "960                1.3                        51.4            -57.5   \n",
       "\n",
       "     RotoWire Projection  ...  Performance Variability Vs Season  \\\n",
       "2                  10.51  ...                                 37   \n",
       "5                  18.42  ...                                 22   \n",
       "11                 20.68  ...                                 29   \n",
       "14                 19.60  ...                                  1   \n",
       "15                 11.49  ...                                 22   \n",
       "..                   ...  ...                                ...   \n",
       "941                17.39  ...                                 30   \n",
       "943                14.39  ...                                  0   \n",
       "950                19.25  ...                                  9   \n",
       "952                22.55  ...                                  7   \n",
       "960                21.04  ...                                 16   \n",
       "\n",
       "     Home Advantage Factor Projection Difference Momentum  \\\n",
       "2                        0                         -21.60   \n",
       "5                        0                           8.06   \n",
       "11                       0                          11.78   \n",
       "14                      49                          10.00   \n",
       "15                      47                           0.11   \n",
       "..                     ...                            ...   \n",
       "941                      0                           4.87   \n",
       "943                     50                          -5.67   \n",
       "950                     51                           1.01   \n",
       "952                      0                          -0.19   \n",
       "960                     51                          -6.37   \n",
       "\n",
       "     Predictive Confidence  Recent Performance Trend  Site Lean Disagreement  \\\n",
       "2                 9.833333                       0.0                      12   \n",
       "5                -9.000000                       0.0                      13   \n",
       "11               -6.266667                       0.0                      21   \n",
       "14               -4.933333                       0.0                      17   \n",
       "15              -20.700000                       0.0                      37   \n",
       "..                     ...                       ...                     ...   \n",
       "941              -2.966667                       0.0                      21   \n",
       "943               1.100000                       0.2                       5   \n",
       "950               0.566667                       0.0                      18   \n",
       "952               2.800000                       0.0                      18   \n",
       "960               0.266667                       0.0                       5   \n",
       "\n",
       "     Implied Probability Discrepancy  Betting Consensus Less  \\\n",
       "2                                  2               51.333333   \n",
       "5                                  2               50.000000   \n",
       "11                                 4               52.000000   \n",
       "14                                 2               49.750000   \n",
       "15                                 6               48.333333   \n",
       "..                               ...                     ...   \n",
       "941                                4               52.000000   \n",
       "943                                0               48.666667   \n",
       "950                                4               48.666667   \n",
       "952                                4               49.500000   \n",
       "960                                0               49.000000   \n",
       "\n",
       "     Betting Consensus More  Betting Line Variance  \n",
       "2                 48.666667                   0.25  \n",
       "5                 50.000000                   0.70  \n",
       "11                48.000000                   0.00  \n",
       "14                50.250000                   0.00  \n",
       "15                51.666667                   0.00  \n",
       "..                      ...                    ...  \n",
       "941               48.000000                   0.25  \n",
       "943               51.333333                   0.00  \n",
       "950               51.333333                   0.00  \n",
       "952               50.500000                   0.20  \n",
       "960               51.000000                   0.00  \n",
       "\n",
       "[243 rows x 65 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_just_market= df_just_market.drop(columns=['Market Name'])#['over']\n",
    "df_just_market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a41e6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df_just_market.select_dtypes(include=['int64', 'float64']).columns\n",
    "df_just_market[numeric_columns] = df_just_market[numeric_columns].apply(pd.to_numeric, errors='coerce', downcast='float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42a332a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df_just_market.select_dtypes(include=['object']).columns\n",
    "df_just_market[categorical_columns] = df_just_market[categorical_columns].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dbda2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns in the DataFrame to float\n",
    "df_just_market = df_just_market.apply(lambda x: x.replace(-1, np.nan).astype(float))\n",
    "df_just_market.fillna(-1, inplace=True)\n",
    "# If you want to convert -1 directly to float without replacing with NaN, you can skip the replacement part:\n",
    "# df_just_market = df_just_market.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83de633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_just_market.drop(columns=['over'])\n",
    "y=df_just_market['over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c09f3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    " encoded_data, encoder, scaler = autoencode_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "307f5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencode_features(data, num_features=10):\n",
    "    # Preprocess data: Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "    # Dimensionality specifics\n",
    "    input_dim = data_scaled.shape[1]\n",
    "    encoding_dim = num_features\n",
    "\n",
    "    # Building the autoencoder\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "    # Encoder model\n",
    "    encoder = Model(input_layer, encoded)\n",
    "\n",
    "    # Compile autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "    # Configure early stopping\n",
    "    early_stopping = EarlyStopping(monitor='loss', min_delta=0.0001, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "    # Train the autoencoder\n",
    "    autoencoder.fit(data_scaled, data_scaled, epochs=500, batch_size=256, shuffle=True, verbose=0, callbacks=[early_stopping], use_multiprocessing=True)\n",
    "\n",
    "    # Encode the data\n",
    "    encoded_data = encoder.predict(data_scaled, verbose=False, use_multiprocessing=True)\n",
    "\n",
    "    return encoded_data, encoder, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "574ae6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# Drop features \n",
    "X_filtered = X.drop(to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00b29d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize RFECV\n",
    "rfecv = RFECV(estimator=model, step=1, cv=5, scoring='accuracy', min_features_to_select=1,n_jobs =-1)\n",
    "\n",
    "rfecv.fit(X_filtered, y)\n",
    "\n",
    "# Transform the data\n",
    "X_rfecv = rfecv.transform(X_filtered)\n",
    "\n",
    "# Find the optimal number of features\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05af46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_filtered, y)\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_filtered.columns)\n",
    "\n",
    "# Keep top n most important features, n determined from RFECV\n",
    "n = rfecv.n_features_\n",
    "top_n_features = feature_importances.nlargest(n).index\n",
    "\n",
    "X_embedded = X_filtered[top_n_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6eee9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_rfecv and X_embedded are your DataFrames after RFECV and Embedded method respectively\n",
    "# Ensure that the features are in the form of DataFrame for easier handling\n",
    "X_combined = pd.DataFrame(X_rfecv, columns=top_n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2163f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = X_combined\n",
    "combined['over'] = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b0c2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.concat([X_combined.drop(columns=['over']),pd.DataFrame(encoded_data)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "857eab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import PyroBayesianLogisticRegression, LeaveOneOutCrossValidationBobby,KFoldCrossValidationBobby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9befe3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.295993450993451"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blr = PyroBayesianLogisticRegression(n_steps = 1000,lr=0.001, batch_size=100)\n",
    "loocv = KFoldCrossValidationBobby(blr,n_jobs=-1,n_splits=15)\n",
    "score = loocv.cross_validate(x_test,y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bda006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  27 | elapsed:   27.0s remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  27 | elapsed:   27.0s remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  27 | elapsed:   36.6s remaining:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  27 | elapsed:   37.2s remaining:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  27 | elapsed:   38.2s remaining:   13.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0\n",
      "Best Parameters: {'n_steps': 500, 'lr': 0.001, 'batch_size': 10, 'score': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:   38.4s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   38.5s finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "# from your_module import PyroBayesianLogisticRegression, KFoldCrossValidationBobby  # Ensure correct import\n",
    "\n",
    "# Assuming X, y are defined somewhere above, and represent your dataset\n",
    "X, y = np.array([...]), np.array([...])  # Replace with your actual data\n",
    "\n",
    "# Define the grid of hyperparameters to search over\n",
    "n_steps_options = [500, 1000, 1500]\n",
    "lr_options = [0.001, 0.005, 0.01]\n",
    "batch_size_options = [10, 50, len(X)]  # Adjust based on your dataset size\n",
    "\n",
    "def evaluate_model(n_steps, lr, batch_size, X, y):\n",
    "    try:\n",
    "        \"\"\"\n",
    "        Function to train and evaluate the model given a set of hyperparameters.\n",
    "        Returns a dictionary containing the hyperparameters and the corresponding score.\n",
    "        \"\"\"\n",
    "        blr = PyroBayesianLogisticRegression(n_steps=n_steps, lr=lr, batch_size=batch_size)\n",
    "        loocv = KFoldCrossValidationBobby(blr, n_jobs=2, n_splits=4)  # Adjust as needed\n",
    "        score = loocv.cross_validate(x_test, y)\n",
    "        return {'n_steps': n_steps, 'lr': lr, 'batch_size': batch_size, 'score': score}\n",
    "    \n",
    "    except:\n",
    "        return {'n_steps': n_steps, 'lr': lr, 'batch_size': batch_size, 'score': 0}\n",
    "    \n",
    "# Use Joblib's Parallel and delayed to parallelize the evaluation across the grid\n",
    "results = Parallel(n_jobs=-1, verbose=9)(\n",
    "    delayed(evaluate_model)(n_steps, lr, batch_size, X, y)\n",
    "    for n_steps in n_steps_options\n",
    "    for lr in lr_options\n",
    "    for batch_size in batch_size_options\n",
    ")\n",
    "\n",
    "# Find the best hyperparameter set based on the score\n",
    "best_result = max(results, key=lambda x: x['score'])\n",
    "\n",
    "print(\"Best Score:\", best_result['score'])\n",
    "print(\"Best Parameters:\", best_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "0bc08574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3a998_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3a998\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3a998_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_3a998_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3a998_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_3a998_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3a998_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_3a998_row1_col1\" class=\"data row1 col1\" >over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3a998_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_3a998_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3a998_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_3a998_row3_col1\" class=\"data row3 col1\" >(243, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3a998_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_3a998_row4_col1\" class=\"data row4 col1\" >(243, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3a998_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_3a998_row5_col1\" class=\"data row5 col1\" >(170, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3a998_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_3a998_row6_col1\" class=\"data row6 col1\" >(73, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3a998_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_3a998_row7_col1\" class=\"data row7 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3a998_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_3a998_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3a998_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_3a998_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3a998_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_3a998_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_3a998_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_3a998_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_3a998_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_3a998_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_3a998_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_3a998_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_3a998_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_3a998_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_3a998_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_3a998_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_3a998_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_3a998_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_3a998_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_3a998_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a998_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_3a998_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_3a998_row18_col1\" class=\"data row18 col1\" >8b11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b26865a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "clf1 = setup(combined, target='over', session_id=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "164de5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2e81e th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2e81e_row0_col0, #T_2e81e_row0_col3, #T_2e81e_row0_col5, #T_2e81e_row1_col0, #T_2e81e_row1_col1, #T_2e81e_row1_col2, #T_2e81e_row1_col3, #T_2e81e_row1_col4, #T_2e81e_row1_col5, #T_2e81e_row1_col6, #T_2e81e_row1_col7, #T_2e81e_row2_col0, #T_2e81e_row2_col1, #T_2e81e_row2_col2, #T_2e81e_row2_col3, #T_2e81e_row2_col4, #T_2e81e_row2_col5, #T_2e81e_row2_col6, #T_2e81e_row2_col7, #T_2e81e_row3_col0, #T_2e81e_row3_col1, #T_2e81e_row3_col2, #T_2e81e_row3_col4, #T_2e81e_row3_col6, #T_2e81e_row3_col7, #T_2e81e_row4_col0, #T_2e81e_row4_col1, #T_2e81e_row4_col2, #T_2e81e_row4_col3, #T_2e81e_row4_col4, #T_2e81e_row4_col5, #T_2e81e_row4_col6, #T_2e81e_row4_col7, #T_2e81e_row5_col0, #T_2e81e_row5_col1, #T_2e81e_row5_col2, #T_2e81e_row5_col3, #T_2e81e_row5_col4, #T_2e81e_row5_col5, #T_2e81e_row5_col6, #T_2e81e_row5_col7, #T_2e81e_row6_col0, #T_2e81e_row6_col1, #T_2e81e_row6_col2, #T_2e81e_row6_col3, #T_2e81e_row6_col4, #T_2e81e_row6_col5, #T_2e81e_row6_col6, #T_2e81e_row6_col7, #T_2e81e_row7_col0, #T_2e81e_row7_col1, #T_2e81e_row7_col2, #T_2e81e_row7_col3, #T_2e81e_row7_col4, #T_2e81e_row7_col5, #T_2e81e_row7_col6, #T_2e81e_row7_col7, #T_2e81e_row8_col0, #T_2e81e_row8_col1, #T_2e81e_row8_col2, #T_2e81e_row8_col3, #T_2e81e_row8_col4, #T_2e81e_row8_col5, #T_2e81e_row8_col6, #T_2e81e_row8_col7, #T_2e81e_row9_col0, #T_2e81e_row9_col1, #T_2e81e_row9_col2, #T_2e81e_row9_col3, #T_2e81e_row9_col4, #T_2e81e_row9_col5, #T_2e81e_row9_col6, #T_2e81e_row9_col7, #T_2e81e_row10_col0, #T_2e81e_row10_col1, #T_2e81e_row10_col2, #T_2e81e_row10_col3, #T_2e81e_row10_col4, #T_2e81e_row10_col5, #T_2e81e_row10_col6, #T_2e81e_row10_col7, #T_2e81e_row11_col0, #T_2e81e_row11_col1, #T_2e81e_row11_col2, #T_2e81e_row11_col3, #T_2e81e_row11_col4, #T_2e81e_row11_col5, #T_2e81e_row11_col6, #T_2e81e_row11_col7, #T_2e81e_row12_col0, #T_2e81e_row12_col1, #T_2e81e_row12_col2, #T_2e81e_row12_col3, #T_2e81e_row12_col4, #T_2e81e_row12_col5, #T_2e81e_row12_col6, #T_2e81e_row12_col7, #T_2e81e_row13_col0, #T_2e81e_row13_col1, #T_2e81e_row13_col2, #T_2e81e_row13_col3, #T_2e81e_row13_col4, #T_2e81e_row13_col5, #T_2e81e_row13_col6, #T_2e81e_row13_col7, #T_2e81e_row14_col0, #T_2e81e_row14_col1, #T_2e81e_row14_col2, #T_2e81e_row14_col3, #T_2e81e_row14_col4, #T_2e81e_row14_col5, #T_2e81e_row14_col6, #T_2e81e_row14_col7, #T_2e81e_row15_col0, #T_2e81e_row15_col1, #T_2e81e_row15_col2, #T_2e81e_row15_col3, #T_2e81e_row15_col4, #T_2e81e_row15_col5, #T_2e81e_row15_col6, #T_2e81e_row15_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2e81e_row0_col1, #T_2e81e_row0_col2, #T_2e81e_row0_col4, #T_2e81e_row0_col6, #T_2e81e_row0_col7, #T_2e81e_row3_col3, #T_2e81e_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_2e81e_row0_col8, #T_2e81e_row1_col8, #T_2e81e_row2_col8, #T_2e81e_row4_col8, #T_2e81e_row5_col8, #T_2e81e_row6_col8, #T_2e81e_row7_col8, #T_2e81e_row8_col8, #T_2e81e_row9_col8, #T_2e81e_row10_col8, #T_2e81e_row11_col8, #T_2e81e_row12_col8, #T_2e81e_row13_col8, #T_2e81e_row14_col8, #T_2e81e_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_2e81e_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2e81e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2e81e_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_2e81e_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_2e81e_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_2e81e_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_2e81e_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_2e81e_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_2e81e_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_2e81e_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_2e81e_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row0\" class=\"row_heading level0 row0\" >dt</th>\n",
       "      <td id=\"T_2e81e_row0_col0\" class=\"data row0 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_2e81e_row0_col1\" class=\"data row0 col1\" >0.5588</td>\n",
       "      <td id=\"T_2e81e_row0_col2\" class=\"data row0 col2\" >0.5590</td>\n",
       "      <td id=\"T_2e81e_row0_col3\" class=\"data row0 col3\" >0.5458</td>\n",
       "      <td id=\"T_2e81e_row0_col4\" class=\"data row0 col4\" >0.5380</td>\n",
       "      <td id=\"T_2e81e_row0_col5\" class=\"data row0 col5\" >0.5358</td>\n",
       "      <td id=\"T_2e81e_row0_col6\" class=\"data row0 col6\" >0.1180</td>\n",
       "      <td id=\"T_2e81e_row0_col7\" class=\"data row0 col7\" >0.1201</td>\n",
       "      <td id=\"T_2e81e_row0_col8\" class=\"data row0 col8\" >0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row1\" class=\"row_heading level0 row1\" >dummy</th>\n",
       "      <td id=\"T_2e81e_row1_col0\" class=\"data row1 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_2e81e_row1_col1\" class=\"data row1 col1\" >0.5235</td>\n",
       "      <td id=\"T_2e81e_row1_col2\" class=\"data row1 col2\" >0.5000</td>\n",
       "      <td id=\"T_2e81e_row1_col3\" class=\"data row1 col3\" >0.0000</td>\n",
       "      <td id=\"T_2e81e_row1_col4\" class=\"data row1 col4\" >0.0000</td>\n",
       "      <td id=\"T_2e81e_row1_col5\" class=\"data row1 col5\" >0.0000</td>\n",
       "      <td id=\"T_2e81e_row1_col6\" class=\"data row1 col6\" >0.0000</td>\n",
       "      <td id=\"T_2e81e_row1_col7\" class=\"data row1 col7\" >0.0000</td>\n",
       "      <td id=\"T_2e81e_row1_col8\" class=\"data row1 col8\" >0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row2\" class=\"row_heading level0 row2\" >knn</th>\n",
       "      <td id=\"T_2e81e_row2_col0\" class=\"data row2 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_2e81e_row2_col1\" class=\"data row2 col1\" >0.5059</td>\n",
       "      <td id=\"T_2e81e_row2_col2\" class=\"data row2 col2\" >0.5403</td>\n",
       "      <td id=\"T_2e81e_row2_col3\" class=\"data row2 col3\" >0.4097</td>\n",
       "      <td id=\"T_2e81e_row2_col4\" class=\"data row2 col4\" >0.4830</td>\n",
       "      <td id=\"T_2e81e_row2_col5\" class=\"data row2 col5\" >0.4313</td>\n",
       "      <td id=\"T_2e81e_row2_col6\" class=\"data row2 col6\" >0.0038</td>\n",
       "      <td id=\"T_2e81e_row2_col7\" class=\"data row2 col7\" >0.0058</td>\n",
       "      <td id=\"T_2e81e_row2_col8\" class=\"data row2 col8\" >0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row3\" class=\"row_heading level0 row3\" >svm</th>\n",
       "      <td id=\"T_2e81e_row3_col0\" class=\"data row3 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_2e81e_row3_col1\" class=\"data row3 col1\" >0.5000</td>\n",
       "      <td id=\"T_2e81e_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_2e81e_row3_col3\" class=\"data row3 col3\" >0.7917</td>\n",
       "      <td id=\"T_2e81e_row3_col4\" class=\"data row3 col4\" >0.4900</td>\n",
       "      <td id=\"T_2e81e_row3_col5\" class=\"data row3 col5\" >0.5969</td>\n",
       "      <td id=\"T_2e81e_row3_col6\" class=\"data row3 col6\" >0.0293</td>\n",
       "      <td id=\"T_2e81e_row3_col7\" class=\"data row3 col7\" >0.0067</td>\n",
       "      <td id=\"T_2e81e_row3_col8\" class=\"data row3 col8\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row4\" class=\"row_heading level0 row4\" >gbc</th>\n",
       "      <td id=\"T_2e81e_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_2e81e_row4_col1\" class=\"data row4 col1\" >0.5000</td>\n",
       "      <td id=\"T_2e81e_row4_col2\" class=\"data row4 col2\" >0.5167</td>\n",
       "      <td id=\"T_2e81e_row4_col3\" class=\"data row4 col3\" >0.4944</td>\n",
       "      <td id=\"T_2e81e_row4_col4\" class=\"data row4 col4\" >0.4824</td>\n",
       "      <td id=\"T_2e81e_row4_col5\" class=\"data row4 col5\" >0.4807</td>\n",
       "      <td id=\"T_2e81e_row4_col6\" class=\"data row4 col6\" >-0.0008</td>\n",
       "      <td id=\"T_2e81e_row4_col7\" class=\"data row4 col7\" >-0.0013</td>\n",
       "      <td id=\"T_2e81e_row4_col8\" class=\"data row4 col8\" >0.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "      <td id=\"T_2e81e_row5_col0\" class=\"data row5 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_2e81e_row5_col1\" class=\"data row5 col1\" >0.4882</td>\n",
       "      <td id=\"T_2e81e_row5_col2\" class=\"data row5 col2\" >0.4778</td>\n",
       "      <td id=\"T_2e81e_row5_col3\" class=\"data row5 col3\" >0.4069</td>\n",
       "      <td id=\"T_2e81e_row5_col4\" class=\"data row5 col4\" >0.4817</td>\n",
       "      <td id=\"T_2e81e_row5_col5\" class=\"data row5 col5\" >0.4239</td>\n",
       "      <td id=\"T_2e81e_row5_col6\" class=\"data row5 col6\" >-0.0321</td>\n",
       "      <td id=\"T_2e81e_row5_col7\" class=\"data row5 col7\" >-0.0283</td>\n",
       "      <td id=\"T_2e81e_row5_col8\" class=\"data row5 col8\" >0.1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row6\" class=\"row_heading level0 row6\" >catboost</th>\n",
       "      <td id=\"T_2e81e_row6_col0\" class=\"data row6 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_2e81e_row6_col1\" class=\"data row6 col1\" >0.4824</td>\n",
       "      <td id=\"T_2e81e_row6_col2\" class=\"data row6 col2\" >0.4597</td>\n",
       "      <td id=\"T_2e81e_row6_col3\" class=\"data row6 col3\" >0.4083</td>\n",
       "      <td id=\"T_2e81e_row6_col4\" class=\"data row6 col4\" >0.4838</td>\n",
       "      <td id=\"T_2e81e_row6_col5\" class=\"data row6 col5\" >0.4214</td>\n",
       "      <td id=\"T_2e81e_row6_col6\" class=\"data row6 col6\" >-0.0417</td>\n",
       "      <td id=\"T_2e81e_row6_col7\" class=\"data row6 col7\" >-0.0327</td>\n",
       "      <td id=\"T_2e81e_row6_col8\" class=\"data row6 col8\" >2.6590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row7\" class=\"row_heading level0 row7\" >nb</th>\n",
       "      <td id=\"T_2e81e_row7_col0\" class=\"data row7 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_2e81e_row7_col1\" class=\"data row7 col1\" >0.4765</td>\n",
       "      <td id=\"T_2e81e_row7_col2\" class=\"data row7 col2\" >0.4069</td>\n",
       "      <td id=\"T_2e81e_row7_col3\" class=\"data row7 col3\" >0.2361</td>\n",
       "      <td id=\"T_2e81e_row7_col4\" class=\"data row7 col4\" >0.4086</td>\n",
       "      <td id=\"T_2e81e_row7_col5\" class=\"data row7 col5\" >0.2886</td>\n",
       "      <td id=\"T_2e81e_row7_col6\" class=\"data row7 col6\" >-0.0666</td>\n",
       "      <td id=\"T_2e81e_row7_col7\" class=\"data row7 col7\" >-0.0791</td>\n",
       "      <td id=\"T_2e81e_row7_col8\" class=\"data row7 col8\" >0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row8\" class=\"row_heading level0 row8\" >xgboost</th>\n",
       "      <td id=\"T_2e81e_row8_col0\" class=\"data row8 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_2e81e_row8_col1\" class=\"data row8 col1\" >0.4765</td>\n",
       "      <td id=\"T_2e81e_row8_col2\" class=\"data row8 col2\" >0.4875</td>\n",
       "      <td id=\"T_2e81e_row8_col3\" class=\"data row8 col3\" >0.4194</td>\n",
       "      <td id=\"T_2e81e_row8_col4\" class=\"data row8 col4\" >0.4496</td>\n",
       "      <td id=\"T_2e81e_row8_col5\" class=\"data row8 col5\" >0.4275</td>\n",
       "      <td id=\"T_2e81e_row8_col6\" class=\"data row8 col6\" >-0.0541</td>\n",
       "      <td id=\"T_2e81e_row8_col7\" class=\"data row8 col7\" >-0.0544</td>\n",
       "      <td id=\"T_2e81e_row8_col8\" class=\"data row8 col8\" >0.2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row9\" class=\"row_heading level0 row9\" >rf</th>\n",
       "      <td id=\"T_2e81e_row9_col0\" class=\"data row9 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_2e81e_row9_col1\" class=\"data row9 col1\" >0.4647</td>\n",
       "      <td id=\"T_2e81e_row9_col2\" class=\"data row9 col2\" >0.4812</td>\n",
       "      <td id=\"T_2e81e_row9_col3\" class=\"data row9 col3\" >0.3958</td>\n",
       "      <td id=\"T_2e81e_row9_col4\" class=\"data row9 col4\" >0.4379</td>\n",
       "      <td id=\"T_2e81e_row9_col5\" class=\"data row9 col5\" >0.4044</td>\n",
       "      <td id=\"T_2e81e_row9_col6\" class=\"data row9 col6\" >-0.0779</td>\n",
       "      <td id=\"T_2e81e_row9_col7\" class=\"data row9 col7\" >-0.0758</td>\n",
       "      <td id=\"T_2e81e_row9_col8\" class=\"data row9 col8\" >0.1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row10\" class=\"row_heading level0 row10\" >ada</th>\n",
       "      <td id=\"T_2e81e_row10_col0\" class=\"data row10 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_2e81e_row10_col1\" class=\"data row10 col1\" >0.4471</td>\n",
       "      <td id=\"T_2e81e_row10_col2\" class=\"data row10 col2\" >0.4076</td>\n",
       "      <td id=\"T_2e81e_row10_col3\" class=\"data row10 col3\" >0.4458</td>\n",
       "      <td id=\"T_2e81e_row10_col4\" class=\"data row10 col4\" >0.4166</td>\n",
       "      <td id=\"T_2e81e_row10_col5\" class=\"data row10 col5\" >0.4215</td>\n",
       "      <td id=\"T_2e81e_row10_col6\" class=\"data row10 col6\" >-0.1073</td>\n",
       "      <td id=\"T_2e81e_row10_col7\" class=\"data row10 col7\" >-0.1098</td>\n",
       "      <td id=\"T_2e81e_row10_col8\" class=\"data row10 col8\" >0.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row11\" class=\"row_heading level0 row11\" >lr</th>\n",
       "      <td id=\"T_2e81e_row11_col0\" class=\"data row11 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_2e81e_row11_col1\" class=\"data row11 col1\" >0.4235</td>\n",
       "      <td id=\"T_2e81e_row11_col2\" class=\"data row11 col2\" >0.4417</td>\n",
       "      <td id=\"T_2e81e_row11_col3\" class=\"data row11 col3\" >0.3222</td>\n",
       "      <td id=\"T_2e81e_row11_col4\" class=\"data row11 col4\" >0.3554</td>\n",
       "      <td id=\"T_2e81e_row11_col5\" class=\"data row11 col5\" >0.3300</td>\n",
       "      <td id=\"T_2e81e_row11_col6\" class=\"data row11 col6\" >-0.1602</td>\n",
       "      <td id=\"T_2e81e_row11_col7\" class=\"data row11 col7\" >-0.1746</td>\n",
       "      <td id=\"T_2e81e_row11_col8\" class=\"data row11 col8\" >0.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row12\" class=\"row_heading level0 row12\" >ridge</th>\n",
       "      <td id=\"T_2e81e_row12_col0\" class=\"data row12 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_2e81e_row12_col1\" class=\"data row12 col1\" >0.4235</td>\n",
       "      <td id=\"T_2e81e_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_2e81e_row12_col3\" class=\"data row12 col3\" >0.3222</td>\n",
       "      <td id=\"T_2e81e_row12_col4\" class=\"data row12 col4\" >0.3554</td>\n",
       "      <td id=\"T_2e81e_row12_col5\" class=\"data row12 col5\" >0.3300</td>\n",
       "      <td id=\"T_2e81e_row12_col6\" class=\"data row12 col6\" >-0.1602</td>\n",
       "      <td id=\"T_2e81e_row12_col7\" class=\"data row12 col7\" >-0.1746</td>\n",
       "      <td id=\"T_2e81e_row12_col8\" class=\"data row12 col8\" >0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row13\" class=\"row_heading level0 row13\" >lda</th>\n",
       "      <td id=\"T_2e81e_row13_col0\" class=\"data row13 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_2e81e_row13_col1\" class=\"data row13 col1\" >0.4235</td>\n",
       "      <td id=\"T_2e81e_row13_col2\" class=\"data row13 col2\" >0.4472</td>\n",
       "      <td id=\"T_2e81e_row13_col3\" class=\"data row13 col3\" >0.3222</td>\n",
       "      <td id=\"T_2e81e_row13_col4\" class=\"data row13 col4\" >0.3554</td>\n",
       "      <td id=\"T_2e81e_row13_col5\" class=\"data row13 col5\" >0.3300</td>\n",
       "      <td id=\"T_2e81e_row13_col6\" class=\"data row13 col6\" >-0.1602</td>\n",
       "      <td id=\"T_2e81e_row13_col7\" class=\"data row13 col7\" >-0.1746</td>\n",
       "      <td id=\"T_2e81e_row13_col8\" class=\"data row13 col8\" >0.0220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n",
       "      <td id=\"T_2e81e_row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_2e81e_row14_col1\" class=\"data row14 col1\" >0.4176</td>\n",
       "      <td id=\"T_2e81e_row14_col2\" class=\"data row14 col2\" >0.4125</td>\n",
       "      <td id=\"T_2e81e_row14_col3\" class=\"data row14 col3\" >0.2736</td>\n",
       "      <td id=\"T_2e81e_row14_col4\" class=\"data row14 col4\" >0.3455</td>\n",
       "      <td id=\"T_2e81e_row14_col5\" class=\"data row14 col5\" >0.2984</td>\n",
       "      <td id=\"T_2e81e_row14_col6\" class=\"data row14 col6\" >-0.1764</td>\n",
       "      <td id=\"T_2e81e_row14_col7\" class=\"data row14 col7\" >-0.1911</td>\n",
       "      <td id=\"T_2e81e_row14_col8\" class=\"data row14 col8\" >0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e81e_level0_row15\" class=\"row_heading level0 row15\" >lightgbm</th>\n",
       "      <td id=\"T_2e81e_row15_col0\" class=\"data row15 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_2e81e_row15_col1\" class=\"data row15 col1\" >0.4118</td>\n",
       "      <td id=\"T_2e81e_row15_col2\" class=\"data row15 col2\" >0.3833</td>\n",
       "      <td id=\"T_2e81e_row15_col3\" class=\"data row15 col3\" >0.3319</td>\n",
       "      <td id=\"T_2e81e_row15_col4\" class=\"data row15 col4\" >0.3562</td>\n",
       "      <td id=\"T_2e81e_row15_col5\" class=\"data row15 col5\" >0.3377</td>\n",
       "      <td id=\"T_2e81e_row15_col6\" class=\"data row15 col6\" >-0.1869</td>\n",
       "      <td id=\"T_2e81e_row15_col7\" class=\"data row15 col7\" >-0.1976</td>\n",
       "      <td id=\"T_2e81e_row15_col8\" class=\"data row15 col8\" >0.4180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b25e731100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = compare_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e052769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce232e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7cc09e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bobby\\OneDrive\\T-drive\\Jupyter\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume X and y are your features and target variable\n",
    "# For demonstration, using placeholder variables\n",
    "X = df_combined[[\n",
    "    'Line', 'Site Less', 'Site More', 'Prediction', 'Lean',\n",
    "    'DFS Pickem Sites Factor', 'Sportsbooks Factor', 'RotoWire Projection Factor', \n",
    "    'Hit Rate Factor', 'RotoWire Projection', 'Weighted Hit Rate', 'At Home', \n",
    "    'Average Line Variance', 'Implied Less ', 'Implied More ', 'Hit Rate Last 10', \n",
    "    'Hit Rate Last 10 Outcomes', 'Hit Rate Last 20 Outcomes', 'Hit Rate Last 30 Outcomes', \n",
    "    'Hit Rate Last 5 Outcomes', 'Hit Rate Previous Season', 'Hit Rate Season', \n",
    "    'Hit Rate Vs Opponent', 'RotoWire Projection Difference', 'RotoWire Projection Difference ',\n",
    "    # Add other relevant features\n",
    "]]\n",
    "y = df_combined['over']  # Your binary target variable\n",
    "\n",
    "# Generate interaction terms\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interacted = poly.fit_transform(X)\n",
    "\n",
    "# Get feature names for the interaction terms\n",
    "feature_names = poly.get_feature_names(input_features=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "70bf43c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_interacted, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and fit the RandomForest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "39f8ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top interactions:\n",
      "Prediction Sportsbooks Factor\n",
      "Hit Rate Last 20 Outcomes Hit Rate Previous Season\n",
      "RotoWire Projection Difference RotoWire Projection Difference \n",
      "Hit Rate Last 30 Outcomes Hit Rate Previous Season\n",
      "Hit Rate Previous Season Hit Rate Season\n",
      "Site More Hit Rate Previous Season\n",
      "Site Less Hit Rate Previous Season\n",
      "Line Hit Rate Vs Opponent\n",
      "Site Less Site More\n",
      "RotoWire Projection Hit Rate Season\n"
     ]
    }
   ],
   "source": [
    "# Combine feature names and importances\n",
    "feature_importance_dict = dict(zip(feature_names, importances))\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Filter out and list top interactions (excluding main effects)\n",
    "top_interactions = [feature for feature, importance in sorted_features if \" \" in feature]\n",
    "\n",
    "# Print top interactions\n",
    "print(\"Top interactions:\")\n",
    "for interaction in top_interactions[:10]:  # Adjust the number to list more or fewer top interactions\n",
    "    print(interaction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "de0bd157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      28.8\n",
       "1      32.8\n",
       "2      25.6\n",
       "3       5.6\n",
       "4      20.4\n",
       "       ... \n",
       "962    19.2\n",
       "963    17.2\n",
       "965    19.2\n",
       "966    21.2\n",
       "967    20.4\n",
       "Length: 876, dtype: float64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Weighted sum of recent and previous season hit rates\n",
    "df_combined['Weighted Recent and Season Hit Rate'] = (\n",
    "    0.6 * df_combined['Hit Rate Last 20 Outcomes'].astype(float).apply(lambda x: str(x).count('1')) / 20 +\n",
    "    0.4 * df_combined['Hit Rate Previous Season'].astype(float)\n",
    ")\n",
    "\n",
    "# Example: Trend in RotoWire Projection Difference\n",
    "# This is more complex and might require calculating the change in projection difference over time,\n",
    "# which could involve temporal data not shown here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "db96f38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bobby\\AppData\\Local\\Temp\\ipykernel_20176\\3241764314.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_combined[['BetMGM Less', 'BetRivers Less', 'DraftKings Less', 'FanDuel Less']].mean(axis=1)\n",
      "C:\\Users\\bobby\\AppData\\Local\\Temp\\ipykernel_20176\\3241764314.py:8: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_combined[['BetMGM Line', 'BetRivers Line', 'DraftKings Line', 'FanDuel Line', 'PointsBet Line']].var(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN\n",
       "       ..\n",
       "962   NaN\n",
       "963   NaN\n",
       "965   NaN\n",
       "966   NaN\n",
       "967   NaN\n",
       "Length: 876, dtype: float64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consensus across betting sites (simplified example)\n",
    "# df_combined['Betting Consensus Less'] = \n",
    "df_combined[['BetMGM Less', 'BetRivers Less', 'DraftKings Less', 'FanDuel Less']].mean(axis=1)\n",
    "# df_combined['Betting Consensus More'] = df_combined[['BetMGM More %', 'BetRivers More %', 'DraftKings More %', 'FanDuel More %']].mean(axis=1)\n",
    "\n",
    "# # Divergence in betting lines across sites (variance)\n",
    "# df_combined['Betting Line Variance'] = \n",
    "df_combined[['BetMGM Line', 'BetRivers Line', 'DraftKings Line', 'FanDuel Line', 'PointsBet Line']].var(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5ef534cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        7.5\n",
       "5       -6.5\n",
       "11      -2.5\n",
       "14      -0.2\n",
       "15     -30.9\n",
       "       ...  \n",
       "941      -10\n",
       "943      2.2\n",
       "950      2.4\n",
       "952      7.7\n",
       "960      1.3\n",
       "Name: Sportsbooks Factor, Length: 243, dtype: object"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_just_market['Prediction'] \n",
    "df_just_market['Sportsbooks Factor'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce606b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "248adc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.5101832399626518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Selecting features and target variable\n",
    "X = df_combined[['Line', 'Site Less', 'Site More', 'Prediction', 'Lean', 'DFS Pickem Sites Factor', 'Sportsbooks Factor', 'RotoWire Projection Factor', 'Hit Rate Factor', 'RotoWire Projection', 'Weighted Hit Rate', 'At Home', 'Average Line Variance', 'Implied Less ', 'Implied More ', 'Hit Rate Last 10', 'Hit Rate Last 10 Outcomes', 'Hit Rate Last 20 Outcomes', 'Hit Rate Last 30 Outcomes', 'Hit Rate Last 5 Outcomes', 'Hit Rate Previous Season', 'Hit Rate Season', 'Hit Rate Vs Opponent', 'RotoWire Projection Difference', 'RotoWire Projection Difference ', 'PrizePicks', 'PrizePicks Line', 'Underdog', 'Underdog Line', 'DraftKings Pick6', 'DraftKings Pick6 Line', 'BetMGM Line', 'BetMGM Less', 'BetMGM More', 'BetMGM Less ', 'BetMGM More ', 'BetRivers Line', 'BetRivers Less', 'BetRivers More', 'BetRivers Less ', 'BetRivers More ', 'DraftKings Line', 'DraftKings Less', 'DraftKings More', 'DraftKings Less ', 'DraftKings More ', 'FanDuel Line', 'FanDuel Less', 'FanDuel More', 'FanDuel Less ', 'FanDuel More ', 'PointsBet Line', 'PointsBet Less', 'PointsBet More', 'PointsBet Less ', 'PointsBet More ']]\n",
    "y = df_combined['over']\n",
    "\n",
    "# Generate interaction terms\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interacted = poly.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_interacted, y, test_size=0.3, random_state=42)\n",
    "\n",
    "### Modeling with Random Forest (or choose another classifier)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'ROC AUC Score: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "66a9857b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.250e+01, -1.220e+02, -1.370e+02, ...,  5.300e+03,  4.700e+03,\n",
       "         2.491e+03],\n",
       "       [ 1.750e+01, -1.210e+02, -1.390e+02, ..., -5.880e+03, -6.120e+03,\n",
       "         2.499e+03],\n",
       "       [ 8.500e+00, -1.360e+02, -1.240e+02, ..., -5.880e+03, -6.120e+03,\n",
       "         2.499e+03],\n",
       "       ...,\n",
       "       [ 3.500e+00, -1.300e+02, -1.290e+02, ..., -5.750e+03, -5.750e+03,\n",
       "         2.500e+03],\n",
       "       [ 1.500e+00, -1.520e+02, -1.120e+02, ...,  1.000e+00,  1.000e+00,\n",
       "         1.000e+00],\n",
       "       [ 2.500e+00, -1.430e+02, -1.180e+02, ..., -5.610e+03, -5.390e+03,\n",
       "         2.499e+03]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_interacted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
